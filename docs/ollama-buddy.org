<<Top>>

Next: [[#Introduction][Introduction]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

* Ollama Buddy [[#Ollama-Buddy][¶]]
:PROPERTIES:
:CUSTOM_ID: Ollama-Buddy
:CLASS: top
:END:
Ollama Buddy is a comprehensive Emacs package that provides seamless
integration with Ollama, allowing you to leverage powerful large
language models (LLMs) directly within your Emacs workflow.

<<SEC_Contents>>
** Table of Contents
:PROPERTIES:
:CUSTOM_ID: table-of-contents
:CLASS: contents-heading
:END:

- [[#Introduction][1 Introduction]]
  - [[#What-is-Ollama-Buddy_003f][1.1 What is Ollama Buddy?]]
  - [[#Why-Use-Ollama-Buddy_003f][1.2 Why Use Ollama Buddy?]]
  - [[#Prerequisites][1.3 Prerequisites]]
- [[#Installation][2 Installation]]
  - [[#Installing-Ollama][2.1 Installing Ollama]]
  - [[#Package-Installation][2.2 Package Installation]]
    - [[#Using-package_002eel][2.2.1 Using package.el]]
    - [[#Using-use_002dpackage][2.2.2 Using use-package]]
    - [[#Manual-Installation][2.2.3 Manual Installation]]
  - [[#Dependencies][2.3 Dependencies]]
  - [[#API-Key-Setup][2.4 API Key Setup]]
- [[#Configuration][3 Configuration]]
  - [[#Basic-Configuration][3.1 Basic Configuration]]
  - [[#Display-Options][3.2 Display Options]]
  - [[#Directory-Configuration][3.3 Directory Configuration]]
  - [[#History-and-Session-Configuration][3.4 History and Session
    Configuration]]
  - [[#Context-Management-Configuration][3.5 Context Management
    Configuration]]
  - [[#External-API-Configuration][3.6 External API Configuration]]
  - [[#Awesome-ChatGPT-Prompts-Configuration][3.7 Awesome ChatGPT
    Prompts Configuration]]
- [[#Quick-Start][4 Quick Start]]
  - [[#Basic-Usage][4.1 Basic Usage]]
  - [[#Common-Operations][4.2 Common Operations]]
- [[#Core-Features][5 Core Features]]
  - [[#Chat-Interface-1][5.1 Chat Interface]]
  - [[#Pre_002dbuilt-Commands][5.2 Pre-built Commands]]
  - [[#Model-Management][5.3 Model Management]]
  - [[#Parameter-Control-1][5.4 Parameter Control]]
  - [[#Roles-and-Custom-Commands][5.5 Roles and Custom Commands]]
  - [[#Prompt-Template-Collections][5.6 Prompt Template Collections]]
  - [[#External-API-Integration][5.7 External API Integration]]
- [[#Chat-Interface][6 Chat Interface]]
  - [[#Opening-the-Chat][6.1 Opening the Chat]]
  - [[#Interface-Overview][6.2 Interface Overview]]
  - [[#Sending-Prompts][6.3 Sending Prompts]]
  - [[#System-Prompts][6.4 System Prompts]]
  - [[#Markdown-to-Org-Conversion][6.5 Markdown to Org Conversion]]
  - [[#Reasoning-Visibility-Control][6.6 Reasoning Visibility Control]]
- [[#Working-with-Models][7 Working with Models]]
  - [[#Available-Models][7.1 Available Models]]
  - [[#Switching-Models][7.2 Switching Models]]
  - [[#Local-vs_002e-Cloud-Models][7.3 Local vs. Cloud Models]]
  - [[#Managing-Models][7.4 Managing Models]]
  - [[#Pulling-New-Models][7.5 Pulling New Models]]
  - [[#Importing-GGUF-Files][7.6 Importing GGUF Files]]
  - [[#Multishot-Mode][7.7 Multishot Mode]]
- [[#Context-Management][8 Context Management]]
  - [[#Understanding-Context-Windows][8.1 Understanding Context
    Windows]]
  - [[#Context-Size-Detection][8.2 Context Size Detection]]
  - [[#Enabling-Context-Monitoring][8.3 Enabling Context Monitoring]]
  - [[#Context-Management-Commands][8.4 Context Management Commands]]
  - [[#Token-Estimation][8.5 Token Estimation]]
  - [[#Managing-Context-in-Practice][8.6 Managing Context in Practice]]
    - [[#Workflow-Strategies][8.6.1 Workflow Strategies]]
      - [[#Paste_002dand_002dSend-Approach][8.6.1.1 Paste-and-Send
        Approach]]
      - [[#Preemptive-Checking][8.6.1.2 Preemptive Checking]]
      - [[#History-Length-Management][8.6.1.3 History Length
        Management]]
    - [[#Using-num_005fctx-Parameter][8.6.2 Using num_ctx Parameter]]
  - [[#Context-Display-Configuration][8.7 Context Display
    Configuration]]
  - [[#Fallback-Context-Sizes][8.8 Fallback Context Sizes]]
  - [[#Troubleshooting-Context-Issues][8.9 Troubleshooting Context
    Issues]]
- [[#Parameter-Control][9 Parameter Control]]
  - [[#Understanding-Parameters][9.1 Understanding Parameters]]
  - [[#Viewing-Current-Parameters][9.2 Viewing Current Parameters]]
  - [[#Editing-Parameters][9.3 Editing Parameters]]
  - [[#Parameter-Profiles][9.4 Parameter Profiles]]
  - [[#Command_002dSpecific-Parameters][9.5 Command-Specific
    Parameters]]
  - [[#Reset-Parameters][9.6 Reset Parameters]]
  - [[#Displaying-Parameters-in-Header][9.7 Displaying Parameters in
    Header]]
- [[#Session-Management][10 Session Management]]
  - [[#Understanding-Sessions][10.1 Understanding Sessions]]
  - [[#Creating-a-New-Session][10.2 Creating a New Session]]
  - [[#Saving-a-Session][10.3 Saving a Session]]
  - [[#Loading-a-Session][10.4 Loading a Session]]
  - [[#Managing-Sessions][10.5 Managing Sessions]]
  - [[#Conversation-History][10.6 Conversation History]]
- [[#Roles-and-Commands][11 Roles and Commands]]
  - [[#Understanding-Roles][11.1 Understanding Roles]]
  - [[#Role-File-Naming-Convention][11.2 Role File Naming Convention]]
  - [[#Built_002din-Commands][11.3 Built-in Commands]]
  - [[#Creating-Custom-Roles][11.4 Creating Custom Roles]]
    - [[#Interactive-Role-Creator][11.4.1 Interactive Role Creator]]
    - [[#Manual-Role-Creation][11.4.2 Manual Role Creation]]
  - [[#Switching-Roles][11.5 Switching Roles]]
  - [[#Managing-Role-Files][11.6 Managing Role Files]]
  - [[#Advanced-Role-Customization][11.7 Advanced Role Customization]]
    - [[#Command_002dSpecific-Models][11.7.1 Command-Specific Models]]
    - [[#Command_002dSpecific-Parameters-1][11.7.2 Command-Specific
      Parameters]]
    - [[#Creating-New-Commands][11.7.3 Creating New Commands]]
  - [[#Role-Examples][11.8 Role Examples]]
    - [[#Programming-Role][11.8.1 Programming Role]]
    - [[#Writing-Role][11.8.2 Writing Role]]
  - [[#Tips-for-Effective-Role-Usage][11.9 Tips for Effective Role
    Usage]]
- [[#Fabric-Pattern-Integration][12 Fabric Pattern Integration]]
  - [[#What-are-Fabric-Patterns_003f][12.1 What are Fabric Patterns?]]
  - [[#Setting-Up-Fabric-Integration][12.2 Setting Up Fabric
    Integration]]
  - [[#Using-Fabric-Patterns][12.3 Using Fabric Patterns]]
  - [[#Browsing-Available-Patterns][12.4 Browsing Available Patterns]]
  - [[#Viewing-Pattern-Details][12.5 Viewing Pattern Details]]
  - [[#Updating-Patterns][12.6 Updating Patterns]]
  - [[#Using-Patterns-by-Category][12.7 Using Patterns by Category]]
- [[#Awesome-ChatGPT-Prompts][13 Awesome ChatGPT Prompts]]
  - [[#What-is-Awesome-ChatGPT-Prompts_003f][13.1 What is Awesome
    ChatGPT Prompts?]]
  - [[#Setting-Up-Awesome-ChatGPT-Prompts][13.2 Setting Up Awesome
    ChatGPT Prompts]]
  - [[#Using-Awesome-ChatGPT-Prompts][13.3 Using Awesome ChatGPT
    Prompts]]
  - [[#Browsing-Available-Prompts][13.4 Browsing Available Prompts]]
  - [[#Categorized-Browsing][13.5 Categorized Browsing]]
  - [[#Viewing-Prompt-Details][13.6 Viewing Prompt Details]]
  - [[#Updating-Prompts][13.7 Updating Prompts]]
  - [[#Setting-Without-Sending][13.8 Setting Without Sending]]
  - [[#Example-Usage][13.9 Example Usage]]
- [[#ChatGPT-and-Claude-Support][14 ChatGPT and Claude Support]]
  - [[#Overview][14.1 Overview]]
  - [[#Setting-Up-API-Access][14.2 Setting Up API Access]]
    - [[#Secure-API-Key-Storage][14.2.1 Secure API Key Storage]]
    - [[#Direct-Configuration][14.2.2 Direct Configuration]]
  - [[#Selecting-Commercial-Models][14.3 Selecting Commercial Models]]
  - [[#Configuring-Commercial-Models][14.4 Configuring Commercial
    Models]]
    - [[#OpenAI-Configuration][14.4.1 OpenAI Configuration]]
    - [[#Claude-Configuration][14.4.2 Claude Configuration]]
  - [[#History-Management][14.5 History Management]]
  - [[#Improved-Error-Handling][14.6 Improved Error Handling]]
- [[#Advanced-Usage][15 Advanced Usage]]
  - [[#Managing-Token-Usage][15.1 Managing Token Usage]]
  - [[#Customizing-the-Interface][15.2 Customizing the Interface]]
    - [[#Interface-Level][15.2.1 Interface Level]]
    - [[#Model-Colors][15.2.2 Model Colors]]
    - [[#Debug-Mode][15.2.3 Debug Mode]]
  - [[#Editing-Conversation-History][15.3 Editing Conversation History]]
  - [[#Advanced-System-Prompt-Management][15.4 Advanced System Prompt
    Management]]
    - [[#Setting-a-system-prompt-without-sending][15.4.1 Setting a
      system prompt without sending]]
    - [[#Using-a-system-prompt-from-Fabric][15.4.2 Using a system prompt
      from Fabric]]
  - [[#Using-Direct-API-Access][15.5 Using Direct API Access]]
- [[#API-Reference][16 API Reference]]
  - [[#Interactive-Functions][16.1 Interactive Functions]]
  - [[#Core-Functions][16.2 Core Functions]]
  - [[#Customization-Functions][16.3 Customization Functions]]
- [[#FAQ][17 Frequently Asked Questions]]
  - [[#General-Questions][17.1 General Questions]]
    - [[#What-is-the-difference-between-Ollama-Buddy-and-other-AI-assistants_003f][17.1.1
      What is the difference between Ollama Buddy and other AI
      assistants?]]
    - [[#Does-Ollama-Buddy-require-an-internet-connection_003f][17.1.2
      Does Ollama Buddy require an internet connection?]]
    - [[#Which-models-work-best-with-Ollama-Buddy_003f][17.1.3 Which
      models work best with Ollama Buddy?]]
    - [[#How-much-RAM-do-I-need_003f][17.1.4 How much RAM do I need?]]
  - [[#Usage-Questions][17.2 Usage Questions]]
    - [[#How-do-I-cancel-a-request-that_0027s-taking-too-long_003f][17.2.1
      How do I cancel a request that's taking too long?]]
    - [[#How-can-I-save-my-conversations_003f][17.2.2 How can I save my
      conversations?]]
    - [[#Can-I-use-multiple-models-in-the-same-conversation_003f][17.2.3
      Can I use multiple models in the same conversation?]]
    - [[#How-do-I-clear-the-conversation-history_003f][17.2.4 How do I
      clear the conversation history?]]
    - [[#How-can-I-create-a-custom-command_003f][17.2.5 How can I create
      a custom command?]]
    - [[#How-can-I-manage-context-windows_003f][17.2.6 How can I manage
      context windows?]]
    - [[#What-happens-when-I-exceed-the-context-limit_003f][17.2.7 What
      happens when I exceed the context limit?]]
  - [[#Troubleshooting-1][17.3 Troubleshooting]]
    - [[#Ollama-Buddy-shows-_0022OFFLINE_0022-status][17.3.1 Ollama
      Buddy shows "OFFLINE" status]]
    - [[#Responses-are-slow-or-the-model-seems-to-hang][17.3.2 Responses
      are slow or the model seems to hang]]
    - [[#Getting-_0022error-parsing-model_0022-when-pulling-a-model][17.3.3
      Getting "error parsing model" when pulling a model]]
    - [[#Model-responses-are-low-quality-or-truncated][17.3.4 Model
      responses are low quality or truncated]]
- [[#Troubleshooting][18 Troubleshooting]]
  - [[#Common-Issues][18.1 Common Issues]]
    - [[#Connection-Problems][18.1.1 Connection Problems]]
    - [[#Model-Problems][18.1.2 Model Problems]]
    - [[#Interface-Issues][18.1.3 Interface Issues]]
  - [[#Debugging][18.2 Debugging]]
    - [[#Enable-Debug-Mode][18.2.1 Enable Debug Mode]]
    - [[#Check-Logs][18.2.2 Check Logs]]
    - [[#Report-Issues][18.2.3 Report Issues]]
- [[#Contributing][19 Contributing]]
  - [[#Getting-Started][19.1 Getting Started]]
  - [[#Development-Setup][19.2 Development Setup]]
    - [[#Required-Tools][19.2.1 Required Tools]]
    - [[#Recommended-Packages][19.2.2 Recommended Packages]]
  - [[#Coding-Guidelines][19.3 Coding Guidelines]]
  - [[#Testing][19.4 Testing]]
    - [[#Run-Existing-Tests][19.4.1 Run Existing Tests]]
    - [[#Adding-New-Tests][19.4.2 Adding New Tests]]
  - [[#Feature-Requests-and-Bug-Reports][19.5 Feature Requests and Bug
    Reports]]
- [[#Index][Index]]

--------------

<<Introduction>>

Next: [[#Installation][Installation]], Previous: [[#Top][Ollama Buddy]],
Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 1 Introduction [[#Introduction-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Introduction-1
:CLASS: chapter
:END:
- [[#What-is-Ollama-Buddy_003f][What is Ollama Buddy?]]
- [[#Why-Use-Ollama-Buddy_003f][Why Use Ollama Buddy?]]
- [[#Prerequisites][Prerequisites]]

<<What-is-Ollama-Buddy_003f>>
*** 1.1 What is Ollama Buddy? [[#What-is-Ollama-Buddy_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: what-is-ollama-buddy
:CLASS: section
:END:
Ollama Buddy is an Emacs package that provides a friendly AI assistant
interface to Ollama, a tool for running large language models (LLMs)
locally on your computer. It allows you to interact with AI models
directly from within Emacs for various tasks such as:

- Code refactoring and explanation
- Writing assistance and proofreading
- Generating Git commit messages
- Dictionary lookups and language assistance
- Custom AI-powered workflows via roles
- Using pre-built prompt templates from Fabric
- Utilizing Awesome ChatGPT Prompts
- Integrating with Claude and OpenAI's commercial APIs

Instead of context-switching to web interfaces or terminal applications,
Ollama Buddy brings the power of local LLMs right into your Emacs
workflow.

<<Why-Use-Ollama-Buddy_003f>>
*** 1.2 Why Use Ollama Buddy? [[#Why-Use-Ollama-Buddy_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: why-use-ollama-buddy
:CLASS: section
:END:
- *Privacy*: All interactions happen locally with Ollama - no data sent
  to external services unless you use commercial APIs
- *Integration*: Seamlessly fits into your existing Emacs workflow
- *Flexibility*: Supports multiple models, parameter tuning, and custom
  commands
- *Efficiency*: Quick access to AI assistance without leaving your
  editor
- *Extensibility*: Create custom roles and commands for your specific
  needs

<<Prerequisites>>
*** 1.3 Prerequisites [[#Prerequisites][¶]]
:PROPERTIES:
:CUSTOM_ID: prerequisites
:CLASS: section
:END:
Before using Ollama Buddy, you need:

- Emacs 28.1 or later
- Ollama installed and running on your system (see
  [[https://ollama.ai]])
- At least one language model pulled into Ollama
- (Optional) API keys for OpenAI or Claude if you want to use those
  services

--------------

<<Installation>>

Next: [[#Configuration][Configuration]], Previous:
[[#Introduction][Introduction]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 2 Installation [[#Installation-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Installation-1
:CLASS: chapter
:END:
- [[#Installing-Ollama][Installing Ollama]]
- [[#Package-Installation][Package Installation]]
- [[#Dependencies][Dependencies]]
- [[#API-Key-Setup][API Key Setup]]

<<Installing-Ollama>>
*** 2.1 Installing Ollama [[#Installing-Ollama][¶]]
:PROPERTIES:
:CUSTOM_ID: installing-ollama
:CLASS: section
:END:
Before installing Ollama Buddy, you need to install Ollama itself:

1. Visit [[https://ollama.ai]] and download the installer for your
   platform
2. Install and run Ollama according to the instructions
3. Pull at least one model using =ollama pull llama3:latest= (or another
   model of your choice)

<<Package-Installation>>
*** 2.2 Package Installation [[#Package-Installation][¶]]
:PROPERTIES:
:CUSTOM_ID: package-installation
:CLASS: section
:END:
- [[#Using-package_002eel][Using package.el]]
- [[#Using-use_002dpackage][Using use-package]]
- [[#Manual-Installation][Manual Installation]]

<<Using-package_002eel>>
**** 2.2.1 Using package.el [[#Using-package_002eel][¶]]
:PROPERTIES:
:CUSTOM_ID: using-package.el
:CLASS: subsection
:END:
The recommended way to install Ollama Buddy is through MELPA:

#+begin_src example-preformatted
M-x package-install RET ollama-buddy RET
#+end_src

<<Using-use_002dpackage>>
**** 2.2.2 Using use-package [[#Using-use_002dpackage][¶]]
:PROPERTIES:
:CUSTOM_ID: using-use-package
:CLASS: subsection
:END:
If you use =use-package=, add the following to your Emacs configuration:

#+begin_src example-preformatted
(use-package ollama-buddy
  :ensure t
  :bind ("C-c o" . ollama-buddy-menu))
#+end_src

With a default model:

#+begin_src example-preformatted
(use-package ollama-buddy
  :ensure t
  :bind ("C-c o" . ollama-buddy-menu)
  :custom (ollama-buddy-default-model "llama3:latest"))
#+end_src

<<Manual-Installation>>
**** 2.2.3 Manual Installation [[#Manual-Installation][¶]]
:PROPERTIES:
:CUSTOM_ID: manual-installation
:CLASS: subsection
:END:
To install manually:

1. Clone the repository:

   #+begin_src example-preformatted
   git clone https://github.com/captainflasmr/ollama-buddy.git
   #+end_src

2. Add to your configuration:

   #+begin_src example-preformatted
   (add-to-list 'load-path "/path/to/ollama-buddy")
   (require 'ollama-buddy)
   (global-set-key (kbd "C-c o") #'ollama-buddy-menu)
   #+end_src

<<Dependencies>>
*** 2.3 Dependencies [[#Dependencies][¶]]
:PROPERTIES:
:CUSTOM_ID: dependencies
:CLASS: section
:END:
Ollama Buddy requires the following Emacs packages:

- transient
- json
- cl-lib

These should be automatically installed if you use package.el or
use-package.

<<API-Key-Setup>>
*** 2.4 API Key Setup [[#API-Key-Setup][¶]]
:PROPERTIES:
:CUSTOM_ID: api-key-setup
:CLASS: section
:END:
If you want to use OpenAI or Claude integration, you'll need to set up
API keys securely:

1. Use Emacs built-in auth-source for secure storage
2. Add to your auth sources (e.g., ~/.authinfo.gpg):

   #+begin_src example-preformatted
   machine api.openai.com login apikey password YOUR_OPENAI_API_KEY_HERE
   machine api.anthropic.com login apikey password YOUR_CLAUDE_API_KEY_HERE
   #+end_src

3. Alternatively, set the variables directly (less secure):

   #+begin_src example-preformatted
   (setq ollama-buddy-openai-api-key "your-openai-key")
   (setq ollama-buddy-claude-api-key "your-claude-key")
   #+end_src

--------------

<<Configuration>>

Next: [[#Quick-Start][Quick Start]], Previous:
[[#Installation][Installation]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 3 Configuration [[#Configuration-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Configuration-1
:CLASS: chapter
:END:
- [[#Basic-Configuration][Basic Configuration]]
- [[#Display-Options][Display Options]]
- [[#Directory-Configuration][Directory Configuration]]
- [[#History-and-Session-Configuration][History and Session
  Configuration]]
- [[#Context-Management-Configuration][Context Management
  Configuration]]
- [[#External-API-Configuration][External API Configuration]]
- [[#Awesome-ChatGPT-Prompts-Configuration][Awesome ChatGPT Prompts
  Configuration]]

<<Basic-Configuration>>
*** 3.1 Basic Configuration [[#Basic-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: basic-configuration
:CLASS: section
:END:
Here are the essential configuration options:

- =ollama-buddy-default-model= :: Set your preferred default model.

  #+begin_src example-preformatted
  (setq ollama-buddy-default-model "llama3:latest")
  #+end_src

- =ollama-buddy-host= :: Host where Ollama server is running (default:
  "localhost").

  #+begin_src example-preformatted
  (setq ollama-buddy-host "localhost")
  #+end_src

- =ollama-buddy-port= :: Port where Ollama server is running (default:
  11434).

  #+begin_src example-preformatted
  (setq ollama-buddy-port 11434)
  #+end_src

<<Display-Options>>
*** 3.2 Display Options [[#Display-Options][¶]]
:PROPERTIES:
:CUSTOM_ID: display-options
:CLASS: section
:END:
Customize the appearance and behavior of Ollama Buddy:

- =ollama-buddy-convert-markdown-to-org= :: Whether to automatically
  convert markdown to org-mode format in responses (default: t).

  #+begin_src example-preformatted
  (setq ollama-buddy-convert-markdown-to-org t)
  #+end_src

- =ollama-buddy-enable-model-colors= :: Whether to show model names with
  distinctive colors (default: t).

  #+begin_src example-preformatted
  (setq ollama-buddy-enable-model-colors t)
  #+end_src

- =ollama-buddy-display-token-stats= :: Whether to display token usage
  statistics after responses (default: nil).

  #+begin_src example-preformatted
  (setq ollama-buddy-display-token-stats t)
  #+end_src

- =ollama-buddy-interface-level= :: Level of interface complexity
  ('basic or 'advanced).

  #+begin_src example-preformatted
  (setq ollama-buddy-interface-level 'advanced)
  #+end_src

<<Directory-Configuration>>
*** 3.3 Directory Configuration [[#Directory-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: directory-configuration
:CLASS: section
:END:
Customize where Ollama Buddy stores its files:

- =ollama-buddy-sessions-directory= :: Directory for storing session
  files.

  #+begin_src example-preformatted
  (setq ollama-buddy-sessions-directory 
        (expand-file-name "ollama-buddy-sessions" user-emacs-directory))
  #+end_src

- =ollama-buddy-roles-directory= :: Directory for storing role preset
  files.

  #+begin_src example-preformatted
  (setq ollama-buddy-roles-directory
        (expand-file-name "ollama-buddy-presets" user-emacs-directory))
  #+end_src

- =ollama-buddy-modelfile-directory= :: Directory for storing temporary
  Modelfiles.

  #+begin_src example-preformatted
  (setq ollama-buddy-modelfile-directory
        (expand-file-name "ollama-buddy-modelfiles" user-emacs-directory))
  #+end_src

- =ollama-buddy-awesome-local-dir= :: Directory for storing Awesome
  ChatGPT Prompts.

  #+begin_src example-preformatted
  (setq ollama-buddy-awesome-local-dir
        (expand-file-name "awesome-chatgpt-prompts" user-emacs-directory))
  #+end_src

<<History-and-Session-Configuration>>
*** 3.4 History and Session Configuration [[#History-and-Session-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: history-and-session-configuration
:CLASS: section
:END:
Configure how conversation history is managed:

- =ollama-buddy-history-enabled= :: Whether to use conversation history
  in Ollama requests (default: t).

  #+begin_src example-preformatted
  (setq ollama-buddy-history-enabled t)
  #+end_src

- =ollama-buddy-max-history-length= :: Maximum number of message pairs
  to keep in conversation history (default: 10).

  #+begin_src example-preformatted
  (setq ollama-buddy-max-history-length 10)
  #+end_src

- =ollama-buddy-show-history-indicator= :: Whether to show the history
  indicator in the header line (default: t).

  #+begin_src example-preformatted
  (setq ollama-buddy-show-history-indicator t)
  #+end_src

<<Context-Management-Configuration>>
*** 3.5 Context Management Configuration [[#Context-Management-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: context-management-configuration
:CLASS: section
:END:
Configure how Ollama Buddy handles context management:

- =ollama-buddy-show-context-percentage= :: Whether to show context
  percentage in the status bar (default: nil).

  #+begin_src example-preformatted
  (setq ollama-buddy-show-context-percentage t)
  #+end_src

- =ollama-buddy-fallback-context-sizes= :: Mapping of model names to
  their default context sizes.

  #+begin_src example-preformatted
  (setq ollama-buddy-fallback-context-sizes
    '(("llama3:8b" . 4096)
      ("codellama:7b" . 8192)))
  #+end_src

- =ollama-buddy-max-history-length= :: Maximum number of message pairs
  to keep (affects context usage).

  #+begin_src example-preformatted
  (setq ollama-buddy-max-history-length 10)
  #+end_src

<<External-API-Configuration>>
*** 3.6 External API Configuration [[#External-API-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: external-api-configuration
:CLASS: section
:END:
For OpenAI and Claude integration:

- =ollama-buddy-openai-api-key= :: Your OpenAI API key.

  #+begin_src example-preformatted
  (setq ollama-buddy-openai-api-key "your-openai-key")
  #+end_src

- =ollama-buddy-claude-api-key= :: Your Claude API key.

  #+begin_src example-preformatted
  (setq ollama-buddy-claude-api-key "your-claude-key")
  #+end_src

- =ollama-buddy-openai-default-model= :: Default model for OpenAI
  requests.

  #+begin_src example-preformatted
  (setq ollama-buddy-openai-default-model "gpt-4")
  #+end_src

- =ollama-buddy-claude-default-model= :: Default model for Claude
  requests.

  #+begin_src example-preformatted
  (setq ollama-buddy-claude-default-model "claude-3-opus-20240229")
  #+end_src

<<Awesome-ChatGPT-Prompts-Configuration>>
*** 3.7 Awesome ChatGPT Prompts Configuration [[#Awesome-ChatGPT-Prompts-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: awesome-chatgpt-prompts-configuration
:CLASS: section
:END:
Configure the Awesome ChatGPT Prompts integration:

- =ollama-buddy-awesome-repo-url= :: URL of the Awesome ChatGPT Prompts
  GitHub repository.

  #+begin_src example-preformatted
  (setq ollama-buddy-awesome-repo-url "https://github.com/f/awesome-chatgpt-prompts.git")
  #+end_src

- =ollama-buddy-awesome-update-on-startup= :: Whether to automatically
  update prompts when Emacs starts.

  #+begin_src example-preformatted
  (setq ollama-buddy-awesome-update-on-startup nil)
  #+end_src

- =ollama-buddy-awesome-categorize-prompts= :: Whether to categorize
  prompts based on common keywords.

  #+begin_src example-preformatted
  (setq ollama-buddy-awesome-categorize-prompts t)
  #+end_src

--------------

<<Quick-Start>>

Next: [[#Core-Features][Core Features]], Previous:
[[#Configuration][Configuration]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 4 Quick Start [[#Quick-Start-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Quick-Start-1
:CLASS: chapter
:END:
- [[#Basic-Usage][Basic Usage]]
- [[#Common-Operations][Common Operations]]

<<Basic-Usage>>
*** 4.1 Basic Usage [[#Basic-Usage][¶]]
:PROPERTIES:
:CUSTOM_ID: basic-usage
:CLASS: section
:END:
1. Launch Ollama Buddy:

   #+begin_src example-preformatted
   M-x ollama-buddy-menu
   #+end_src

   or use your configured keybinding (e.g., =C-c o=).

2. The menu will show available options. Press the corresponding key for
   the action you want.

3. To open the chat interface, press =o= or select "Open Chat".

4. In the chat buffer, type your prompt and press =C-c C-c= to send it.

5. The AI will respond in the chat buffer.

<<Common-Operations>>
*** 4.2 Common Operations [[#Common-Operations][¶]]
:PROPERTIES:
:CUSTOM_ID: common-operations
:CLASS: section
:END:
- Sending text from a file :: Select text in any buffer, then press
  =C-c o= and choose "Send Region" (or press =l=).

- Refactoring code :: Select code, press =C-c o=, then choose "Refactor
  Code" (or press =r=).

- Generating a commit message :: Select your changes, press =C-c o=,
  then choose "Git Commit Message" (or press =g=).

- Changing models :: Press =C-c o= followed by =m= to switch between
  available models.

- Toggling reasoning visibility :: Press =C-c V= to hide or show
  reasoning/thinking sections in responses.

- Using Awesome ChatGPT Prompts :: Select text, press =C-c o=, then =a=
  for the Awesome prompts menu, then =s= to send with a prompt.

- Using Fabric patterns :: Select text, press =C-c o=, then =f= for the
  Fabric menu, then =s= to send with a pattern.

- Getting help :: In the chat buffer, press =C-c h= to display the help
  screen with available commands and models.

--------------

<<Core-Features>>

Next: [[#Chat-Interface][Chat Interface]], Previous:
[[#Quick-Start][Quick Start]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 5 Core Features [[#Core-Features-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Core-Features-1
:CLASS: chapter
:END:
- [[#Chat-Interface-1][Chat Interface]]
- [[#Pre_002dbuilt-Commands][Pre-built Commands]]
- [[#Model-Management][Model Management]]
- [[#Parameter-Control-1][Parameter Control]]
- [[#Roles-and-Custom-Commands][Roles and Custom Commands]]
- [[#Prompt-Template-Collections][Prompt Template Collections]]
- [[#External-API-Integration][External API Integration]]

<<Chat-Interface-1>>
*** 5.1 Chat Interface [[#Chat-Interface-1][¶]]
:PROPERTIES:
:CUSTOM_ID: chat-interface
:CLASS: section
:END:
The chat interface is the main way to interact with Ollama Buddy:

- Persistent conversation with history
- Markdown to Org-mode conversion
- Model-specific colors
- System prompt support
- Parameter customization
- Reasoning/thinking section visibility control
- Context window management and monitoring
- Real-time context usage display
- Context size validation before sending prompts
- Customizable context thresholds and warnings

<<Pre_002dbuilt-Commands>>
*** 5.2 Pre-built Commands [[#Pre_002dbuilt-Commands][¶]]
:PROPERTIES:
:CUSTOM_ID: pre-built-commands
:CLASS: section
:END:
Ollama Buddy comes with several pre-built commands:

- Code Refactoring :: Improves code while maintaining functionality

- Code Description :: Explains what code does and how it works

- Git Commit Messages :: Generates meaningful commit messages from code
  changes

- Dictionary Lookups :: Provides comprehensive word definitions

- Synonym Finder :: Suggests alternative words with context

- Proofreading :: Corrects grammar, style, and spelling

<<Model-Management>>
*** 5.3 Model Management [[#Model-Management][¶]]
:PROPERTIES:
:CUSTOM_ID: model-management
:CLASS: section
:END:
- Switch between any model available in Ollama
- Use ChatGPT and Claude models with API keys
- Pull new models directly from the interface
- View model information and statistics
- Delete models you no longer need
- Import GGUF files to create new models

<<Parameter-Control-1>>
*** 5.4 Parameter Control [[#Parameter-Control-1][¶]]
:PROPERTIES:
:CUSTOM_ID: parameter-control
:CLASS: section
:END:
- Fine-tune model behavior with customizable parameters
- Save and use parameter profiles for different use cases
- Command-specific parameter settings
- Real-time parameter adjustment

<<Roles-and-Custom-Commands>>
*** 5.5 Roles and Custom Commands [[#Roles-and-Custom-Commands][¶]]
:PROPERTIES:
:CUSTOM_ID: roles-and-custom-commands
:CLASS: section
:END:
- Create custom command sets for specific workflows
- Design specialized AI assistants with custom system prompts
- Save and switch between different roles
- Share role configurations across your team

<<Prompt-Template-Collections>>
*** 5.6 Prompt Template Collections [[#Prompt-Template-Collections][¶]]
:PROPERTIES:
:CUSTOM_ID: prompt-template-collections
:CLASS: section
:END:
- Use pre-built prompt patterns from Fabric project
- Utilize the Awesome ChatGPT Prompts collection
- Apply specialized prompts to your content with one command
- Browse prompts by category

<<External-API-Integration>>
*** 5.7 External API Integration [[#External-API-Integration][¶]]
:PROPERTIES:
:CUSTOM_ID: external-api-integration
:CLASS: section
:END:
- Connect to OpenAI's ChatGPT API
- Connect to Anthropic's Claude API
- Seamlessly switch between local and cloud models
- Secure API key management

--------------

<<Chat-Interface>>

Next: [[#Working-with-Models][Working with Models]], Previous:
[[#Core-Features][Core Features]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 6 Chat Interface [[#Chat-Interface-2][¶]]
:PROPERTIES:
:CUSTOM_ID: Chat-Interface-2
:CLASS: chapter
:END:
- [[#Opening-the-Chat][Opening the Chat]]
- [[#Interface-Overview][Interface Overview]]
- [[#Sending-Prompts][Sending Prompts]]
- [[#System-Prompts][System Prompts]]
- [[#Markdown-to-Org-Conversion][Markdown to Org Conversion]]
- [[#Reasoning-Visibility-Control][Reasoning Visibility Control]]

<<Opening-the-Chat>>
*** 6.1 Opening the Chat [[#Opening-the-Chat][¶]]
:PROPERTIES:
:CUSTOM_ID: opening-the-chat
:CLASS: section
:END:
To open the chat interface:

1. Use =M-x ollama-buddy-menu= or your configured keybinding
2. Press =o= to select "Open Chat"
3. A new buffer will open with the Ollama Buddy chat interface

<<Interface-Overview>>
*** 6.2 Interface Overview [[#Interface-Overview][¶]]
:PROPERTIES:
:CUSTOM_ID: interface-overview
:CLASS: section
:END:
The chat interface consists of:

- A welcome message with available models
- Conversation history (previous prompts and responses)
- A prompt area for entering your queries
- A header line with status information
- A status bar showing context usage (when enabled)
- Context warnings and validation

<<Sending-Prompts>>
*** 6.3 Sending Prompts [[#Sending-Prompts][¶]]
:PROPERTIES:
:CUSTOM_ID: sending-prompts
:CLASS: section
:END:
To send a prompt to the AI:

1. Type your message in the prompt area (after ">> PROMPT:")
2. Press =C-c C-c= to send
3. Wait for the AI to generate a response

You can also:

- Use =M-p= and =M-n= to navigate through prompt history
- Press =C-c k= to cancel a request if it's taking too long

<<System-Prompts>>
*** 6.4 System Prompts [[#System-Prompts][¶]]
:PROPERTIES:
:CUSTOM_ID: system-prompts
:CLASS: section
:END:
System prompts allow you to define the AI's behavior:

- Setting a system prompt :: Type your system prompt, then press =C-c s=

- Viewing the current system prompt :: Press =C-c C-s=

- Resetting the system prompt :: Press =C-c r=

- Using a pre-built prompt :: Use Fabric patterns (=C-c f p=) or Awesome
  ChatGPT prompts (=C-c w p=)

Example system prompt:

#+begin_src example-preformatted
You are a programming expert who specializes in Python. 
Provide concise, efficient solutions with explanations.
#+end_src

<<Markdown-to-Org-Conversion>>
*** 6.5 Markdown to Org Conversion [[#Markdown-to-Org-Conversion][¶]]
:PROPERTIES:
:CUSTOM_ID: markdown-to-org-conversion
:CLASS: section
:END:
By default, Ollama Buddy converts markdown in responses to Org-mode
syntax:

- Code blocks are converted to Org-mode source blocks
- Headers are converted to Org-mode headings
- Lists are properly formatted
- Links are converted to Org-mode format

To toggle this feature:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-markdown-conversion
#+end_src

or press =C-c C-o= in the chat buffer.

<<Reasoning-Visibility-Control>>
*** 6.6 Reasoning Visibility Control [[#Reasoning-Visibility-Control][¶]]
:PROPERTIES:
:CUSTOM_ID: reasoning-visibility-control
:CLASS: section
:END:
Ollama Buddy can hide reasoning/thinking sections in responses, making
the output cleaner:

- Toggle visibility with =C-c V= or
  =M-x ollama-buddy-toggle-reasoning-visibility=
- Configure markers with the =ollama-buddy-reasoning-markers= variable
- When hidden, a status message shows the current reasoning section
  (e.g., "Think...")
- Header line indicates when reasoning is hidden with "REASONING HIDDEN"
  text

This feature helps focus on final answers while preserving the option to
view the full reasoning process.

--------------

<<Working-with-Models>>

Next: [[#Context-Management][Context Management]], Previous:
[[#Chat-Interface][Chat Interface]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 7 Working with Models [[#Working-with-Models-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Working-with-Models-1
:CLASS: chapter
:END:
- [[#Available-Models][Available Models]]
- [[#Switching-Models][Switching Models]]
- [[#Local-vs_002e-Cloud-Models][Local vs. Cloud Models]]
- [[#Managing-Models][Managing Models]]
- [[#Pulling-New-Models][Pulling New Models]]
- [[#Importing-GGUF-Files][Importing GGUF Files]]
- [[#Multishot-Mode][Multishot Mode]]

<<Available-Models>>
*** 7.1 Available Models [[#Available-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: available-models
:CLASS: section
:END:
Ollama Buddy displays available models in the chat interface. Each model
is assigned a letter for quick selection.

To view detailed model information:

#+begin_src example-preformatted
M-x ollama-buddy-show-model-status
#+end_src

or press =C-c v= in the chat buffer.

<<Switching-Models>>
*** 7.2 Switching Models [[#Switching-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: switching-models
:CLASS: section
:END:
To change the current model:

1. Press =C-c m= in the chat buffer
2. Select a model from the completion list
3. The new model will be used for future requests

You can also switch models from the main menu with =m=.

<<Local-vs_002e-Cloud-Models>>
*** 7.3 Local vs. Cloud Models [[#Local-vs_002e-Cloud-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: local-vs.-cloud-models
:CLASS: section
:END:
Ollama Buddy supports both local Ollama models and cloud-based models:

- Local models (via Ollama): llama3, codellama, mistral, etc.
- OpenAI models: gpt-3.5-turbo, gpt-4, etc.
- Claude models: claude-3-opus, claude-3-sonnet, etc.

To use cloud models, you need to configure API keys as described in the
Installation chapter.

<<Managing-Models>>
*** 7.4 Managing Models [[#Managing-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: managing-models
:CLASS: section
:END:
Ollama Buddy provides a comprehensive model management interface. To
access it:

#+begin_src example-preformatted
M-x ollama-buddy-manage-models
#+end_src

or press =C-c W= in the chat buffer.

From this interface, you can:

- See which models are currently running
- Pull new models from Ollama Hub
- Delete models you no longer need
- View detailed model information
- Select models for use

<<Pulling-New-Models>>
*** 7.5 Pulling New Models [[#Pulling-New-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: pulling-new-models
:CLASS: section
:END:
To pull a new model:

1. Open the model management interface with =C-c W=
2. Click "[Pull Any Model]" or press the appropriate key
3. Enter the model name (e.g., "phi:latest", "codellama:7b")
4. Wait for the model to download

<<Importing-GGUF-Files>>
*** 7.6 Importing GGUF Files [[#Importing-GGUF-Files][¶]]
:PROPERTIES:
:CUSTOM_ID: importing-gguf-files
:CLASS: section
:END:
You can import custom GGUF model files:

1. Press =C-c W= to open the model management interface
2. Click "[Import GGUF File]" or press the appropriate key
3. Select the GGUF file from your file system
4. Enter a name for the model
5. Optionally provide model parameters
6. Wait for Ollama to create the model

<<Multishot-Mode>>
*** 7.7 Multishot Mode [[#Multishot-Mode][¶]]
:PROPERTIES:
:CUSTOM_ID: multishot-mode
:CLASS: section
:END:
Multishot mode allows you to send the same prompt to multiple models
simultaneously:

1. Type your prompt in the chat buffer
2. Press =C-c M=
3. Enter the sequence of model letters you want to use (e.g., "a,b,c" to
   use models a, b, and c)
4. Note that each item should be separated with a comma
5. Watch as Ollama Buddy processes your request with each model in
   sequence

--------------

<<Context-Management>>

Next: [[#Parameter-Control][Parameter Control]], Previous:
[[#Working-with-Models][Working with Models]], Up: [[#Top][Ollama
Buddy]]   [[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 8 Context Management [[#Context-Management-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Context-Management-1
:CLASS: chapter
:END:
- [[#Understanding-Context-Windows][Understanding Context Windows]]
- [[#Context-Size-Detection][Context Size Detection]]
- [[#Enabling-Context-Monitoring][Enabling Context Monitoring]]
- [[#Context-Management-Commands][Context Management Commands]]
- [[#Token-Estimation][Token Estimation]]
- [[#Managing-Context-in-Practice][Managing Context in Practice]]
- [[#Context-Display-Configuration][Context Display Configuration]]
- [[#Fallback-Context-Sizes][Fallback Context Sizes]]
- [[#Troubleshooting-Context-Issues][Troubleshooting Context Issues]]

<<Understanding-Context-Windows>>
*** 8.1 Understanding Context Windows [[#Understanding-Context-Windows][¶]]
:PROPERTIES:
:CUSTOM_ID: understanding-context-windows
:CLASS: section
:END:
Context windows define how much text (measured in tokens) a model can
process at once. This includes your current prompt, conversation
history, and any system prompts. Understanding and managing context is
crucial for:

- Preventing errors when context limits are exceeded
- Optimizing model performance for different tasks
- Managing longer conversations efficiently

<<Context-Size-Detection>>
*** 8.2 Context Size Detection [[#Context-Size-Detection][¶]]
:PROPERTIES:
:CUSTOM_ID: context-size-detection
:CLASS: section
:END:
Ollama Buddy uses multiple methods to determine a model's context size:

1. Built-in mappings for popular models (llama3, mistral, codellama,
   etc.)
2. Custom context sizes set via the =num_ctx= parameter
3. Manual configuration through interactive commands
4. Fallback to reasonable defaults (4096 tokens) for unknown models

<<Enabling-Context-Monitoring>>
*** 8.3 Enabling Context Monitoring [[#Enabling-Context-Monitoring][¶]]
:PROPERTIES:
:CUSTOM_ID: enabling-context-monitoring
:CLASS: section
:END:
Context monitoring is disabled by default. To enable it:

#+begin_src example-preformatted
(setq ollama-buddy-show-context-percentage t)
#+end_src

With context monitoring enabled:

- The status bar shows current/max context usage (e.g., "2048/8192")
- Text formatting indicates usage levels:
  - Normal font: Under 85% usage
  - Bold and underlined: 85-100% usage
  - Inverted: At or exceeding 100% usage
- Warnings appear before sending prompts that exceed limits

<<Context-Management-Commands>>
*** 8.4 Context Management Commands [[#Context-Management-Commands][¶]]
:PROPERTIES:
:CUSTOM_ID: context-management-commands
:CLASS: section
:END:
- Show Context Information (C-c C) :: Displays a breakdown of current
  context usage, including:

  - Conversation history token count
  - System prompt token count
  - Current prompt token count
  - Total usage percentage

- Set Model Context Size (C-c $) :: Manually configure the context size
  for a specific model.

- Toggle Context Display (C-c %) :: Show or hide the context percentage
  in the status bar.

<<Token-Estimation>>
*** 8.5 Token Estimation [[#Token-Estimation][¶]]
:PROPERTIES:
:CUSTOM_ID: token-estimation
:CLASS: section
:END:
Ollama Buddy estimates token counts using a heuristic approach:

- Each word is multiplied by 1.3 (following common approximations)
- This provides a reasonable estimate for most use cases
- Actual token counts may vary slightly between models

<<Managing-Context-in-Practice>>
*** 8.6 Managing Context in Practice [[#Managing-Context-in-Practice][¶]]
:PROPERTIES:
:CUSTOM_ID: managing-context-in-practice
:CLASS: section
:END:
- [[#Workflow-Strategies][Workflow Strategies]]
- [[#Using-num_005fctx-Parameter][Using num_ctx Parameter]]

<<Workflow-Strategies>>
**** 8.6.1 Workflow Strategies [[#Workflow-Strategies][¶]]
:PROPERTIES:
:CUSTOM_ID: workflow-strategies
:CLASS: subsection
:END:
- [[#Paste_002dand_002dSend-Approach][Paste-and-Send Approach]]
- [[#Preemptive-Checking][Preemptive Checking]]
- [[#History-Length-Management][History Length Management]]

<<Paste_002dand_002dSend-Approach>>
**** 8.6.1.1 Paste-and-Send Approach [[#Paste_002dand_002dSend-Approach][¶]]
:PROPERTIES:
:CUSTOM_ID: paste-and-send-approach
:CLASS: subsubsection
:END:
1. Paste your content into the chat buffer
2. Press the send keybinding
3. If context is exceeded, you'll get a warning dialog
4. Choose whether to proceed or modify your content

<<Preemptive-Checking>>
**** 8.6.1.2 Preemptive Checking [[#Preemptive-Checking][¶]]
:PROPERTIES:
:CUSTOM_ID: preemptive-checking
:CLASS: subsubsection
:END:
1. Paste your content
2. Use C-c C to check context usage
3. If too high:
   - Trim your current prompt
   - Edit conversation history (C-c J)
   - Switch to a larger context model
   - Adjust system prompt length

<<History-Length-Management>>
**** 8.6.1.3 History Length Management [[#History-Length-Management][¶]]
:PROPERTIES:
:CUSTOM_ID: history-length-management
:CLASS: subsubsection
:END:
Control context by limiting conversation history:

#+begin_src example-preformatted
(setq ollama-buddy-max-history-length 5)
#+end_src

This keeps only the last 5 message pairs, reducing context usage.

<<Using-num_005fctx-Parameter>>
**** 8.6.2 Using num_ctx Parameter [[#Using-num_005fctx-Parameter][¶]]
:PROPERTIES:
:CUSTOM_ID: using-num_ctx-parameter
:CLASS: subsection
:END:
The =num_ctx= parameter allows you to set a specific context size:

1. Access the parameter menu with C-c P
2. Select =num_ctx=
3. Enter your desired context size
4. Ollama Buddy will respect this limit

<<Context-Display-Configuration>>
*** 8.7 Context Display Configuration [[#Context-Display-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: context-display-configuration
:CLASS: section
:END:
Customize how context information is displayed:

- =ollama-buddy-show-context-percentage= :: Whether to show context
  percentage in the status bar (default: nil).

- =ollama-buddy-context-warning-threshold= :: Percentage at which to
  warn about high context usage (default: 90).

- =ollama-buddy-context-error-threshold= :: Percentage at which to block
  sending (default: 100).

<<Fallback-Context-Sizes>>
*** 8.8 Fallback Context Sizes [[#Fallback-Context-Sizes][¶]]
:PROPERTIES:
:CUSTOM_ID: fallback-context-sizes
:CLASS: section
:END:
Ollama Buddy includes predefined context sizes for popular models. You
can customize these via:

#+begin_src example-preformatted
(setq ollama-buddy-fallback-context-sizes
  '(("llama3:8b" . 4096)
    ("codellama:7b" . 8192)
    ("mistral:7b" . 8192)))
#+end_src

<<Troubleshooting-Context-Issues>>
*** 8.9 Troubleshooting Context Issues [[#Troubleshooting-Context-Issues][¶]]
:PROPERTIES:
:CUSTOM_ID: troubleshooting-context-issues
:CLASS: section
:END:
- Context warnings appear unexpectedly :: - Check if you have a long
    system prompt
  - Review conversation history length
  - Verify the model's actual context size
- Model responses are truncated :: - Increase the =num_ctx= parameter
  - Reduce history length with C-c Y
  - Clear some conversation history
- Context calculations seem inaccurate :: - Remember that token
    estimation is approximate
  - Different models may tokenize text differently
  - Use C-c C to see detailed breakdowns

--------------

<<Parameter-Control>>

Next: [[#Session-Management][Session Management]], Previous:
[[#Context-Management][Context Management]], Up: [[#Top][Ollama Buddy]]
  [[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 9 Parameter Control [[#Parameter-Control-2][¶]]
:PROPERTIES:
:CUSTOM_ID: Parameter-Control-2
:CLASS: chapter
:END:
- [[#Understanding-Parameters][Understanding Parameters]]
- [[#Viewing-Current-Parameters][Viewing Current Parameters]]
- [[#Editing-Parameters][Editing Parameters]]
- [[#Parameter-Profiles][Parameter Profiles]]
- [[#Command_002dSpecific-Parameters][Command-Specific Parameters]]
- [[#Reset-Parameters][Reset Parameters]]
- [[#Displaying-Parameters-in-Header][Displaying Parameters in Header]]

<<Understanding-Parameters>>
*** 9.1 Understanding Parameters [[#Understanding-Parameters][¶]]
:PROPERTIES:
:CUSTOM_ID: understanding-parameters
:CLASS: section
:END:
Ollama's models support various parameters that control their behavior:

- temperature :: Controls randomness (0.0-1.0+), higher values produce
  more creative outputs

- top_k :: Limits token selection to top K most probable tokens

- top_p :: Nucleus sampling threshold (0.0-1.0)

- repeat_penalty :: Penalty for repeating tokens (higher values reduce
  repetition)

<<Viewing-Current-Parameters>>
*** 9.2 Viewing Current Parameters [[#Viewing-Current-Parameters][¶]]
:PROPERTIES:
:CUSTOM_ID: viewing-current-parameters
:CLASS: section
:END:
To view all current parameters:

#+begin_src example-preformatted
M-x ollama-buddy-params-display
#+end_src

or press =C-c G= in the chat buffer.

Parameters that have been modified from default values are marked with
an asterisk (*).

<<Editing-Parameters>>
*** 9.3 Editing Parameters [[#Editing-Parameters][¶]]
:PROPERTIES:
:CUSTOM_ID: editing-parameters
:CLASS: section
:END:
To edit parameters:

1. Press =C-c P= to open the parameter menu
2. Select the parameter you want to modify
3. Enter the new value

You can also use =M-x ollama-buddy-params-edit= and select from a
completion list.

<<Parameter-Profiles>>
*** 9.4 Parameter Profiles [[#Parameter-Profiles][¶]]
:PROPERTIES:
:CUSTOM_ID: parameter-profiles
:CLASS: section
:END:
Ollama Buddy comes with predefined parameter profiles for different use
cases:

- Default :: Standard balanced settings

- Creative :: Higher temperature, lower penalties for more creative
  responses

- Precise :: Lower temperature, higher penalties for more deterministic
  responses

To apply a profile:

#+begin_src example-preformatted
M-x ollama-buddy-transient-profile-menu
#+end_src

or press =C-c p= and select a profile.

<<Command_002dSpecific-Parameters>>
*** 9.5 Command-Specific Parameters [[#Command_002dSpecific-Parameters][¶]]
:PROPERTIES:
:CUSTOM_ID: command-specific-parameters
:CLASS: section
:END:
Some commands have pre-configured parameters. For example:

- The "Refactor Code" command uses lower temperature for more
  deterministic results
- The "Creative Writing" command uses higher temperature for more varied
  outputs

These parameters are automatically applied when you use these commands
and restored afterward.

<<Reset-Parameters>>
*** 9.6 Reset Parameters [[#Reset-Parameters][¶]]
:PROPERTIES:
:CUSTOM_ID: reset-parameters
:CLASS: section
:END:
To reset all parameters to default values:

#+begin_src example-preformatted
M-x ollama-buddy-params-reset
#+end_src

or press =C-c K= in the chat buffer.

<<Displaying-Parameters-in-Header>>
*** 9.7 Displaying Parameters in Header [[#Displaying-Parameters-in-Header][¶]]
:PROPERTIES:
:CUSTOM_ID: displaying-parameters-in-header
:CLASS: section
:END:
To toggle whether modified parameters are shown in the header:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-params-in-header
#+end_src

or press =C-c F= in the chat buffer.

--------------

<<Session-Management>>

Next: [[#Roles-and-Commands][Roles and Commands]], Previous:
[[#Parameter-Control][Parameter Control]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 10 Session Management [[#Session-Management-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Session-Management-1
:CLASS: chapter
:END:
- [[#Understanding-Sessions][Understanding Sessions]]
- [[#Creating-a-New-Session][Creating a New Session]]
- [[#Saving-a-Session][Saving a Session]]
- [[#Loading-a-Session][Loading a Session]]
- [[#Managing-Sessions][Managing Sessions]]
- [[#Conversation-History][Conversation History]]

<<Understanding-Sessions>>
*** 10.1 Understanding Sessions [[#Understanding-Sessions][¶]]
:PROPERTIES:
:CUSTOM_ID: understanding-sessions
:CLASS: section
:END:
Sessions in Ollama Buddy allow you to:

- Save the entire conversation history
- Save the current model selection
- Restore previous conversations later
- Switch between different conversation contexts

<<Creating-a-New-Session>>
*** 10.2 Creating a New Session [[#Creating-a-New-Session][¶]]
:PROPERTIES:
:CUSTOM_ID: creating-a-new-session
:CLASS: section
:END:
To start a fresh session:

#+begin_src example-preformatted
M-x ollama-buddy-sessions-new
#+end_src

or press =C-c N= in the chat buffer.

This will clear the current conversation history and let you start
fresh.

<<Saving-a-Session>>
*** 10.3 Saving a Session [[#Saving-a-Session][¶]]
:PROPERTIES:
:CUSTOM_ID: saving-a-session
:CLASS: section
:END:
To save the current session:

#+begin_src example-preformatted
M-x ollama-buddy-sessions-save
#+end_src

or press =C-c S= in the chat buffer.

You'll be prompted to enter a name for the session.

<<Loading-a-Session>>
*** 10.4 Loading a Session [[#Loading-a-Session][¶]]
:PROPERTIES:
:CUSTOM_ID: loading-a-session
:CLASS: section
:END:
To load a previously saved session:

#+begin_src example-preformatted
M-x ollama-buddy-sessions-load
#+end_src

or press =C-c L= in the chat buffer.

You'll be presented with a list of saved sessions to choose from.

<<Managing-Sessions>>
*** 10.5 Managing Sessions [[#Managing-Sessions][¶]]
:PROPERTIES:
:CUSTOM_ID: managing-sessions
:CLASS: section
:END:
To see a list of all saved sessions:

#+begin_src example-preformatted
M-x ollama-buddy-sessions-list
#+end_src

or press =C-c Q= in the chat buffer.

From this view, you can see:

- Session names
- Last modified times
- Which models are used in each session

To delete a session:

#+begin_src example-preformatted
M-x ollama-buddy-sessions-delete
#+end_src

or press =C-c Z= in the chat buffer.

<<Conversation-History>>
*** 10.6 Conversation History [[#Conversation-History][¶]]
:PROPERTIES:
:CUSTOM_ID: conversation-history
:CLASS: section
:END:
Sessions save the conversation history for each model separately.

To view the current conversation history:

#+begin_src example-preformatted
M-x ollama-buddy-history-edit
#+end_src

or press =C-c J= in the chat buffer.

To clear the history:

#+begin_src example-preformatted
M-x ollama-buddy-clear-history
#+end_src

or press =C-c X= in the chat buffer.

To toggle whether history is used in requests:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-history
#+end_src

or press =C-c H= in the chat buffer.

--------------

<<Roles-and-Commands>>

Next: [[#Fabric-Pattern-Integration][Fabric Pattern Integration]],
Previous: [[#Session-Management][Session Management]], Up:
[[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 11 Roles and Commands [[#Roles-and-Commands-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Roles-and-Commands-1
:CLASS: chapter
:END:
- [[#Understanding-Roles][Understanding Roles]]
- [[#Role-File-Naming-Convention][Role File Naming Convention]]
- [[#Built_002din-Commands][Built-in Commands]]
- [[#Creating-Custom-Roles][Creating Custom Roles]]
- [[#Switching-Roles][Switching Roles]]
- [[#Managing-Role-Files][Managing Role Files]]
- [[#Advanced-Role-Customization][Advanced Role Customization]]
- [[#Role-Examples][Role Examples]]
- [[#Tips-for-Effective-Role-Usage][Tips for Effective Role Usage]]

<<Understanding-Roles>>
*** 11.1 Understanding Roles [[#Understanding-Roles][¶]]
:PROPERTIES:
:CUSTOM_ID: understanding-roles
:CLASS: section
:END:
Roles in Ollama Buddy are collections of commands with specific
configurations:

- Each role has its own set of commands
- Commands can use specific models
- Commands can have specialized system prompts
- Commands can have specialized parameters

This allows you to create specialized assistants for different
workflows.

<<Role-File-Naming-Convention>>
*** 11.2 Role File Naming Convention [[#Role-File-Naming-Convention][¶]]
:PROPERTIES:
:CUSTOM_ID: role-file-naming-convention
:CLASS: section
:END:
The file naming convention is critical to understand how roles, preset
files, and menu configurations work together:

- Required filename format :: =ollama-buddy--preset__ROLE-NAME.el=

  - The double underscore =__= separates the prefix from your role name
  - The role name portion becomes the identifier shown when switching
    roles
  - Example: =ollama-buddy--preset__programmer.el= creates a role named
    "programmer"

This naming convention is how Ollama Buddy discovers and identifies role
files. When you run =ollama-buddy-roles-switch-role=, the system:

1. Scans the =ollama-buddy-roles-directory= for files matching the
   pattern
2. Extracts the role name from each filename (the part after =__=)
3. Presents these names in the role selection interface
4. When selected, loads the corresponding file which redefines
   =ollama-buddy-command-definitions=
5. This redefinition immediately changes the available commands in your
   Ollama Buddy menu

The relationship chain works like this:

#+begin_src example-preformatted
ollama-buddy--preset__ROLE-NAME.el → Defines ollama-buddy-command-definitions → Controls menu content
#+end_src

When creating roles using the interactive role creator (=C-c E=), this
naming convention is automatically handled for you. When creating roles
manually, you must follow this pattern for Ollama Buddy to recognize
your role files correctly.

<<Built_002din-Commands>>
*** 11.3 Built-in Commands [[#Built_002din-Commands][¶]]
:PROPERTIES:
:CUSTOM_ID: built-in-commands
:CLASS: section
:END:
Ollama Buddy comes with several built-in commands:

- refactor-code :: Improves code while maintaining functionality

- describe-code :: Explains what code does and how it works

- git-commit :: Generates meaningful commit messages

- dictionary-lookup :: Provides comprehensive word definitions

- synonym :: Suggests alternative words with context

- proofread :: Corrects grammar, style, and spelling

<<Creating-Custom-Roles>>
*** 11.4 Creating Custom Roles [[#Creating-Custom-Roles][¶]]
:PROPERTIES:
:CUSTOM_ID: creating-custom-roles
:CLASS: section
:END:
There are two ways to create custom roles:

- [[#Interactive-Role-Creator][Interactive Role Creator]]
- [[#Manual-Role-Creation][Manual Role Creation]]

<<Interactive-Role-Creator>>
**** 11.4.1 Interactive Role Creator [[#Interactive-Role-Creator][¶]]
:PROPERTIES:
:CUSTOM_ID: interactive-role-creator
:CLASS: subsection
:END:
The most user-friendly approach:

1. Press =C-c E= or run =M-x ollama-buddy-role-creator-create-new-role=
2. Enter a name for your role (e.g., "programmer")
3. For each command you want to add:
   - Specify a command name (e.g., "refactor-code")
   - Choose a key shortcut for the menu
   - Add a description
   - Optionally specify a model
   - Optionally add prompt prefixes and system messages

The interactive creator automatically handles file naming and placement.

<<Manual-Role-Creation>>
**** 11.4.2 Manual Role Creation [[#Manual-Role-Creation][¶]]
:PROPERTIES:
:CUSTOM_ID: manual-role-creation
:CLASS: subsection
:END:
For more advanced customization, create role files manually:

1. Create a file named =ollama-buddy--preset__your-role-name.el= in your
   =ollama-buddy-roles-directory=
2. Structure your file like this:

#+begin_src example-preformatted
;; ollama-buddy preset for role: programmer
(require 'ollama-buddy)

(setq ollama-buddy-command-definitions
  '(
    ;; Standard commands - always include these
    (open-chat
     :key ?o
     :description "Open chat buffer"
     :action ollama-buddy--open-chat)
    
    (show-models
     :key ?v
     :description "View model status"
     :action ollama-buddy-show-model-status)
    
    (switch-role
     :key ?R
     :description "Switch roles"
     :action ollama-buddy-roles-switch-role)
    
    (create-role
     :key ?E
     :description "Create new role"
     :action ollama-buddy-role-creator-create-new-role)
    
    (open-roles-directory
     :key ?D
     :description "Open roles directory"
     :action ollama-buddy-roles-open-directory)
    
    ;; Custom commands for this role
    (refactor-code
     :key ?r
     :description "Refactor code"
     :model "codellama:7b"
     :prompt "Refactor this code to improve readability and efficiency:"
     :system "You are an expert software engineer who improves code quality."
     :action (lambda () (ollama-buddy--send-with-command 'refactor-code)))
    
    (explain-code
     :key ?e
     :description "Explain code"
     :model "deepseek-r1:7b"
     :prompt "Explain what this code does in detail:"
     :system "You are a programming teacher who explains code clearly."
     :action (lambda () (ollama-buddy--send-with-command 'explain-code)))
    
    (git-commit
     :key ?g
     :description "Git commit message"
     :prompt "Write a concise git commit message for these changes:"
     :system "You are a version control expert who creates clear commit messages."
     :action (lambda () (ollama-buddy--send-with-command 'git-commit)))
    ))
#+end_src

<<Switching-Roles>>
*** 11.5 Switching Roles [[#Switching-Roles][¶]]
:PROPERTIES:
:CUSTOM_ID: switching-roles
:CLASS: section
:END:
To switch between roles:

#+begin_src example-preformatted
M-x ollama-buddy-roles-switch-role
#+end_src

or press =C-c R= in the chat buffer.

You'll be presented with a list of available roles to choose from.

<<Managing-Role-Files>>
*** 11.6 Managing Role Files [[#Managing-Role-Files][¶]]
:PROPERTIES:
:CUSTOM_ID: managing-role-files
:CLASS: section
:END:
Roles are stored as Elisp files in the =ollama-buddy-roles-directory=.

To locate your roles directory:

#+begin_src example-preformatted
;; Check where your roles are stored
(message ollama-buddy-roles-directory)
#+end_src

By default, this is set to =~/.emacs.d/ollama-buddy-presets/=, but you
can customize it:

#+begin_src example-preformatted
(setq ollama-buddy-roles-directory "/your/custom/path/to/presets")
#+end_src

To open this directory:

#+begin_src example-preformatted
M-x ollama-buddy-roles-open-directory
#+end_src

or press =C-c D= in the chat buffer.

<<Advanced-Role-Customization>>
*** 11.7 Advanced Role Customization [[#Advanced-Role-Customization][¶]]
:PROPERTIES:
:CUSTOM_ID: advanced-role-customization
:CLASS: section
:END:
- [[#Command_002dSpecific-Models][Command-Specific Models]]
- [[#Command_002dSpecific-Parameters-1][Command-Specific Parameters]]
- [[#Creating-New-Commands][Creating New Commands]]

<<Command_002dSpecific-Models>>
**** 11.7.1 Command-Specific Models [[#Command_002dSpecific-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: command-specific-models
:CLASS: subsection
:END:
Assign specific models to commands for optimal performance:

#+begin_src example-preformatted
(ollama-buddy-add-model-to-menu-entry 'refactor-code "codellama:7b")
#+end_src

<<Command_002dSpecific-Parameters-1>>
**** 11.7.2 Command-Specific Parameters [[#Command_002dSpecific-Parameters-1][¶]]
:PROPERTIES:
:CUSTOM_ID: command-specific-parameters-1
:CLASS: subsection
:END:
Optimize parameters for specific commands:

#+begin_src example-preformatted
(ollama-buddy-add-parameters-to-command 'refactor-code
  'temperature 0.2
  'top_p 0.7
  'repeat_penalty 1.3)
#+end_src

<<Creating-New-Commands>>
**** 11.7.3 Creating New Commands [[#Creating-New-Commands][¶]]
:PROPERTIES:
:CUSTOM_ID: creating-new-commands
:CLASS: subsection
:END:
Add entirely new commands to your menu:

#+begin_src example-preformatted
(ollama-buddy-update-menu-entry 'my-new-command
  :key ?z
  :description "My new awesome command"
  :prompt "Here is what I want you to do:"
  :system "You are an expert system specialized in this task."
  :action (lambda () (ollama-buddy--send-with-command 'my-new-command)))
#+end_src

<<Role-Examples>>
*** 11.8 Role Examples [[#Role-Examples][¶]]
:PROPERTIES:
:CUSTOM_ID: role-examples
:CLASS: section
:END:
- [[#Programming-Role][Programming Role]]
- [[#Writing-Role][Writing Role]]

<<Programming-Role>>
**** 11.8.1 Programming Role [[#Programming-Role][¶]]
:PROPERTIES:
:CUSTOM_ID: programming-role
:CLASS: subsection
:END:
A complete example of a programming-focused role:

#+begin_src example-preformatted
;; ollama-buddy preset for role: programmer
(require 'ollama-buddy)

(setq ollama-buddy-command-definitions
  '(
    ;; Standard commands (abbreviated for clarity)
    (open-chat :key ?o :description "Open chat buffer" :action ollama-buddy--open-chat)
    (show-models :key ?v :description "View model status" :action ollama-buddy-show-model-status)
    (switch-role :key ?R :description "Switch roles" :action ollama-buddy-roles-switch-role)
    
    ;; Programming-specific commands
    (refactor-code
     :key ?r
     :description "Refactor code"
     :model "codellama:7b"
     :prompt "Refactor this code to improve readability and efficiency:"
     :system "You are an expert software engineer who improves code quality."
     :action (lambda () (ollama-buddy--send-with-command 'refactor-code)))
    
    (explain-code
     :key ?e
     :description "Explain code"
     :model "deepseek-r1:7b"
     :prompt "Explain what this code does in detail:"
     :system "You are a programming teacher who explains code clearly."
     :action (lambda () (ollama-buddy--send-with-command 'explain-code)))
    
    (add-tests
     :key ?t
     :description "Generate tests"
     :model "qwen2.5-coder:7b"
     :prompt "Generate unit tests for this code:"
     :system "You are a test automation expert who creates comprehensive test cases."
     :action (lambda () (ollama-buddy--send-with-command 'add-tests)))
    
    (git-commit
     :key ?g
     :description "Git commit message"
     :prompt "Write a concise git commit message for these changes:"
     :action (lambda () (ollama-buddy--send-with-command 'git-commit)))
    ))
#+end_src

<<Writing-Role>>
**** 11.8.2 Writing Role [[#Writing-Role][¶]]
:PROPERTIES:
:CUSTOM_ID: writing-role
:CLASS: subsection
:END:
A complete example of a writing-focused role:

#+begin_src example-preformatted
;; ollama-buddy preset for role: writer
(require 'ollama-buddy)

(setq ollama-buddy-command-definitions
  '(
    ;; Standard commands (abbreviated for clarity)
    (open-chat :key ?o :description "Open chat buffer" :action ollama-buddy--open-chat)
    (show-models :key ?v :description "View model status" :action ollama-buddy-show-model-status)
    (switch-role :key ?R :description "Switch roles" :action ollama-buddy-roles-switch-role)
    
    ;; Writing-focused commands
    (summarize
     :key ?s
     :description "Summarize text"
     :prompt "Summarize the following text in a concise manner:"
     :system "You are an expert at extracting the key points from any text."
     :action (lambda () (ollama-buddy--send-with-command 'summarize)))
    
    (proofread
     :key ?p
     :description "Proofread text"
     :model "deepseek-r1:7b"
     :prompt "Proofread the following text and correct any errors:"
     :system "You are a professional editor who identifies and corrects grammar and style errors."
     :action (lambda () (ollama-buddy--send-with-command 'proofread)))
    
    (rewrite
     :key ?r
     :description "Rewrite text"
     :prompt "Rewrite the following text to improve clarity and flow:"
     :system "You are a skilled writer who can improve any text while preserving its meaning."
     :action (lambda () (ollama-buddy--send-with-command 'rewrite)))
    
    (brainstorm
     :key ?b
     :description "Brainstorm ideas"
     :model "llama3.2:3b"
     :prompt "Generate creative ideas related to the following topic:"
     :parameters ((temperature . 1.0) (top_p . 0.95))
     :action (lambda () (ollama-buddy--send-with-command 'brainstorm)))
    ))
#+end_src

<<Tips-for-Effective-Role-Usage>>
*** 11.9 Tips for Effective Role Usage [[#Tips-for-Effective-Role-Usage][¶]]
:PROPERTIES:
:CUSTOM_ID: tips-for-effective-role-usage
:CLASS: section
:END:
1. Group related commands: Create roles around specific workflows or
   tasks
2. Match models to tasks: Use lightweight models for simple tasks and
   more powerful models for complex ones
3. Customize system prompts: Craft specific system prompts to guide the
   model for each command
4. Use the roles directory: Press =C-c D= to quickly access and manage
   your role files
5. Create specialized roles: Consider roles for programming, writing,
   translation, or domain-specific knowledge

--------------

<<Fabric-Pattern-Integration>>

Next: [[#Awesome-ChatGPT-Prompts][Awesome ChatGPT Prompts]], Previous:
[[#Roles-and-Commands][Roles and Commands]], Up: [[#Top][Ollama Buddy]]
  [[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 12 Fabric Pattern Integration [[#Fabric-Pattern-Integration-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Fabric-Pattern-Integration-1
:CLASS: chapter
:END:
- [[#What-are-Fabric-Patterns_003f][What are Fabric Patterns?]]
- [[#Setting-Up-Fabric-Integration][Setting Up Fabric Integration]]
- [[#Using-Fabric-Patterns][Using Fabric Patterns]]
- [[#Browsing-Available-Patterns][Browsing Available Patterns]]
- [[#Viewing-Pattern-Details][Viewing Pattern Details]]
- [[#Updating-Patterns][Updating Patterns]]
- [[#Using-Patterns-by-Category][Using Patterns by Category]]

<<What-are-Fabric-Patterns_003f>>
*** 12.1 What are Fabric Patterns? [[#What-are-Fabric-Patterns_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: what-are-fabric-patterns
:CLASS: section
:END:
Fabric patterns are pre-defined prompt templates from Daniel Miessler's
Fabric project ([[https://github.com/danielmiessler/fabric]]). They
provide optimized prompts for various tasks, categorized as:

- universal - General-purpose patterns
- code - Programming and development
- writing - Content creation and editing
- analysis - Data and concept examination

<<Setting-Up-Fabric-Integration>>
*** 12.2 Setting Up Fabric Integration [[#Setting-Up-Fabric-Integration][¶]]
:PROPERTIES:
:CUSTOM_ID: setting-up-fabric-integration
:CLASS: section
:END:
To set up Fabric integration:

#+begin_src example-preformatted
M-x ollama-buddy-fabric-setup
#+end_src

This will:

1. Clone the Fabric repository (or set up sparse checkout)
2. Populate available patterns
3. Make patterns available for use

<<Using-Fabric-Patterns>>
*** 12.3 Using Fabric Patterns [[#Using-Fabric-Patterns][¶]]
:PROPERTIES:
:CUSTOM_ID: using-fabric-patterns
:CLASS: section
:END:
To use a Fabric pattern:

#+begin_src example-preformatted
M-x ollama-buddy-fabric-send
#+end_src

or press =C-c f= and then =s=.

You'll be prompted to:

1. Select a pattern
2. Enter text to process (or use selected text)

The pattern will be used as a system prompt for your request.

<<Browsing-Available-Patterns>>
*** 12.4 Browsing Available Patterns [[#Browsing-Available-Patterns][¶]]
:PROPERTIES:
:CUSTOM_ID: browsing-available-patterns
:CLASS: section
:END:
To see all available patterns:

#+begin_src example-preformatted
M-x ollama-buddy-fabric-list-patterns
#+end_src

or press =C-c f= and then =l=.

This shows:

- Pattern names
- Categories
- Descriptions

<<Viewing-Pattern-Details>>
*** 12.5 Viewing Pattern Details [[#Viewing-Pattern-Details][¶]]
:PROPERTIES:
:CUSTOM_ID: viewing-pattern-details
:CLASS: section
:END:
To see the full content of a specific pattern:

#+begin_src example-preformatted
M-x ollama-buddy-fabric-show-pattern
#+end_src

or press =C-c f= and then =v=.

Select a pattern to see:

- The system prompt content
- Full description

<<Updating-Patterns>>
*** 12.6 Updating Patterns [[#Updating-Patterns][¶]]
:PROPERTIES:
:CUSTOM_ID: updating-patterns
:CLASS: section
:END:
To sync with the latest patterns from GitHub:

#+begin_src example-preformatted
M-x ollama-buddy-fabric-sync-patterns
#+end_src

or press =C-c f= and then =S=.

<<Using-Patterns-by-Category>>
*** 12.7 Using Patterns by Category [[#Using-Patterns-by-Category][¶]]
:PROPERTIES:
:CUSTOM_ID: using-patterns-by-category
:CLASS: section
:END:
You can quickly access patterns by category:

- =C-c f u= - Universal patterns
- =C-c f c= - Code patterns
- =C-c f w= - Writing patterns
- =C-c f a= - Analysis patterns

--------------

<<Awesome-ChatGPT-Prompts>>

Next: [[#ChatGPT-and-Claude-Support][ChatGPT and Claude Support]],
Previous: [[#Fabric-Pattern-Integration][Fabric Pattern Integration]],
Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 13 Awesome ChatGPT Prompts [[#Awesome-ChatGPT-Prompts-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Awesome-ChatGPT-Prompts-1
:CLASS: chapter
:END:
- [[#What-is-Awesome-ChatGPT-Prompts_003f][What is Awesome ChatGPT
  Prompts?]]
- [[#Setting-Up-Awesome-ChatGPT-Prompts][Setting Up Awesome ChatGPT
  Prompts]]
- [[#Using-Awesome-ChatGPT-Prompts][Using Awesome ChatGPT Prompts]]
- [[#Browsing-Available-Prompts][Browsing Available Prompts]]
- [[#Categorized-Browsing][Categorized Browsing]]
- [[#Viewing-Prompt-Details][Viewing Prompt Details]]
- [[#Updating-Prompts][Updating Prompts]]
- [[#Setting-Without-Sending][Setting Without Sending]]
- [[#Example-Usage][Example Usage]]

<<What-is-Awesome-ChatGPT-Prompts_003f>>
*** 13.1 What is Awesome ChatGPT Prompts? [[#What-is-Awesome-ChatGPT-Prompts_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: what-is-awesome-chatgpt-prompts
:CLASS: section
:END:
Awesome ChatGPT Prompts is a curated collection of prompt templates
created by the community and maintained in the GitHub repository at
[[https://github.com/f/awesome-chatgpt-prompts]]. These prompts are
designed to make ChatGPT (and other LLMs) act as various specialized
personas or experts, such as:

- Writing professionals (poets, storytellers, copywriters)
- Technical experts (programmers, researchers, scientists)
- Creative professionals (artists, designers, photographers)
- Business experts (marketers, consultants, strategists)
- And many more specialized roles

<<Setting-Up-Awesome-ChatGPT-Prompts>>
*** 13.2 Setting Up Awesome ChatGPT Prompts [[#Setting-Up-Awesome-ChatGPT-Prompts][¶]]
:PROPERTIES:
:CUSTOM_ID: setting-up-awesome-chatgpt-prompts
:CLASS: section
:END:
To set up the Awesome ChatGPT Prompts integration:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-setup
#+end_src

This will:

1. Create a sparse checkout of the Awesome ChatGPT Prompts repository
2. Download only the necessary files (prompts.csv and README)
3. Populate and categorize the available prompts

<<Using-Awesome-ChatGPT-Prompts>>
*** 13.3 Using Awesome ChatGPT Prompts [[#Using-Awesome-ChatGPT-Prompts][¶]]
:PROPERTIES:
:CUSTOM_ID: using-awesome-chatgpt-prompts
:CLASS: section
:END:
To use an Awesome ChatGPT Prompt:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-send
#+end_src

or press =C-c w= and then =s=.

You'll be prompted to:

1. Select a prompt from the categorized list
2. Enter text to process (or use selected text)

The selected prompt will be used as a system prompt for your request,
transforming how the AI responds to your text.

<<Browsing-Available-Prompts>>
*** 13.4 Browsing Available Prompts [[#Browsing-Available-Prompts][¶]]
:PROPERTIES:
:CUSTOM_ID: browsing-available-prompts
:CLASS: section
:END:
To see all available prompts:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-list-prompts
#+end_src

or press =C-c w= and then =l=.

This shows:

- Prompt titles
- Categories
- Preview of prompt content

<<Categorized-Browsing>>
*** 13.5 Categorized Browsing [[#Categorized-Browsing][¶]]
:PROPERTIES:
:CUSTOM_ID: categorized-browsing
:CLASS: section
:END:
Ollama Buddy automatically categorizes the Awesome ChatGPT Prompts into
useful groups:

- writing - For writing, poetry, and creative content
- code - For programming and development
- business - For marketing, entrepreneurship, and business strategy
- academic - For educational and research content
- creative - For artistic and design-related prompts
- philosophy - For philosophical reasoning and ethics
- health - For medical, fitness, and wellness
- legal - For law-related prompts
- finance - For financial advice and analysis
- other - Miscellaneous prompts

To browse by category:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-show-prompts-menu
#+end_src

or press =C-c w= and then =c=.

<<Viewing-Prompt-Details>>
*** 13.6 Viewing Prompt Details [[#Viewing-Prompt-Details][¶]]
:PROPERTIES:
:CUSTOM_ID: viewing-prompt-details
:CLASS: section
:END:
To see the full content of a specific prompt:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-show-prompt
#+end_src

or press =C-c w= and then =v=.

Select a prompt to see its complete template.

<<Updating-Prompts>>
*** 13.7 Updating Prompts [[#Updating-Prompts][¶]]
:PROPERTIES:
:CUSTOM_ID: updating-prompts
:CLASS: section
:END:
To sync with the latest prompts from GitHub:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-sync-prompts
#+end_src

or press =C-c w= and then =S=.

<<Setting-Without-Sending>>
*** 13.8 Setting Without Sending [[#Setting-Without-Sending][¶]]
:PROPERTIES:
:CUSTOM_ID: setting-without-sending
:CLASS: section
:END:
To set a prompt as the system prompt without sending text:

#+begin_src example-preformatted
M-x ollama-buddy-awesome-set-system-prompt
#+end_src

or press =C-c w= and then =p=.

This is useful when you want to set up a specific persona before
starting a conversation.

<<Example-Usage>>
*** 13.9 Example Usage [[#Example-Usage][¶]]
:PROPERTIES:
:CUSTOM_ID: example-usage
:CLASS: section
:END:
Some popular prompts include:

- "Act as a poet" - Transforms your text into poetry
- "Act as a Linux terminal" - Simulates a Linux terminal interface
- "Act as a gaslighter" - Responds in a deliberately confusing manner
- "Act as a javascript console" - Simulates a JavaScript console
- "Act as an English translator" - Translates text to proper English

--------------

<<ChatGPT-and-Claude-Support>>

Next: [[#Advanced-Usage][Advanced Usage]], Previous:
[[#Awesome-ChatGPT-Prompts][Awesome ChatGPT Prompts]], Up:
[[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 14 ChatGPT and Claude Support [[#ChatGPT-and-Claude-Support-1][¶]]
:PROPERTIES:
:CUSTOM_ID: ChatGPT-and-Claude-Support-1
:CLASS: chapter
:END:
- [[#Overview][Overview]]
- [[#Setting-Up-API-Access][Setting Up API Access]]
- [[#Selecting-Commercial-Models][Selecting Commercial Models]]
- [[#Configuring-Commercial-Models][Configuring Commercial Models]]
- [[#History-Management][History Management]]
- [[#Improved-Error-Handling][Improved Error Handling]]

<<Overview>>
*** 14.1 Overview [[#Overview][¶]]
:PROPERTIES:
:CUSTOM_ID: overview
:CLASS: section
:END:
Ollama Buddy integrates with commercial AI services:

- OpenAI's ChatGPT API
- Anthropic's Claude API

This allows you to:

- Use the latest commercial models when needed
- Compare responses between local and cloud models
- Leverage the strengths of different model families

<<Setting-Up-API-Access>>
*** 14.2 Setting Up API Access [[#Setting-Up-API-Access][¶]]
:PROPERTIES:
:CUSTOM_ID: setting-up-api-access
:CLASS: section
:END:
Before using commercial APIs, you need to set up API keys:

- [[#Secure-API-Key-Storage][Secure API Key Storage]]
- [[#Direct-Configuration][Direct Configuration]]

<<Secure-API-Key-Storage>>
**** 14.2.1 Secure API Key Storage [[#Secure-API-Key-Storage][¶]]
:PROPERTIES:
:CUSTOM_ID: secure-api-key-storage
:CLASS: subsection
:END:
The recommended approach is to use Emacs' built-in auth-source:

#+begin_src example-preformatted
;; Add to ~/.authinfo.gpg (encrypted)
machine api.openai.com login apikey password YOUR_OPENAI_API_KEY
machine api.anthropic.com login apikey password YOUR_CLAUDE_API_KEY
#+end_src

<<Direct-Configuration>>
**** 14.2.2 Direct Configuration [[#Direct-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: direct-configuration
:CLASS: subsection
:END:
For testing or temporary use (less secure):

#+begin_src example-preformatted
(setq ollama-buddy-openai-api-key "your-openai-key")
(setq ollama-buddy-claude-api-key "your-claude-key")
#+end_src

<<Selecting-Commercial-Models>>
*** 14.3 Selecting Commercial Models [[#Selecting-Commercial-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: selecting-commercial-models
:CLASS: section
:END:
Both OpenAI and Claude models appear in the model selection list with
special prefixes:

- OpenAI models are prefixed with "openai:"
- Claude models are prefixed with "claude:"

To select a commercial model:

#+begin_src example-preformatted
M-x ollama-buddy--swap-model
#+end_src

or press =C-c m=.

Choose the model from the completion list.

<<Configuring-Commercial-Models>>
*** 14.4 Configuring Commercial Models [[#Configuring-Commercial-Models][¶]]
:PROPERTIES:
:CUSTOM_ID: configuring-commercial-models
:CLASS: section
:END:
- [[#OpenAI-Configuration][OpenAI Configuration]]
- [[#Claude-Configuration][Claude Configuration]]

<<OpenAI-Configuration>>
**** 14.4.1 OpenAI Configuration [[#OpenAI-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: openai-configuration
:CLASS: subsection
:END:
- =ollama-buddy-openai-default-model= :: Default OpenAI model to use
  (e.g., "gpt-4").

  #+begin_src example-preformatted
  (setq ollama-buddy-openai-default-model "gpt-4")
  #+end_src

- =ollama-buddy-openai-temperature= :: Default temperature for OpenAI
  requests (0.0-2.0).

  #+begin_src example-preformatted
  (setq ollama-buddy-openai-temperature 0.7)
  #+end_src

- =ollama-buddy-openai-max-tokens= :: Maximum tokens to generate (nil
  for API default).

  #+begin_src example-preformatted
  (setq ollama-buddy-openai-max-tokens 2000)
  #+end_src

- =ollama-buddy-openai-api-endpoint= :: Custom API endpoint (defaults to
  OpenAI's standard endpoint).

  #+begin_src example-preformatted
  (setq ollama-buddy-openai-api-endpoint "https://api.openai.com/v1/chat/completions")
  #+end_src

<<Claude-Configuration>>
**** 14.4.2 Claude Configuration [[#Claude-Configuration][¶]]
:PROPERTIES:
:CUSTOM_ID: claude-configuration
:CLASS: subsection
:END:
- =ollama-buddy-claude-default-model= :: Default Claude model to use.

  #+begin_src example-preformatted
  (setq ollama-buddy-claude-default-model "claude-3-opus-20240229")
  #+end_src

- =ollama-buddy-claude-temperature= :: Default temperature for Claude
  requests (0.0-1.0).

  #+begin_src example-preformatted
  (setq ollama-buddy-claude-temperature 0.7)
  #+end_src

- =ollama-buddy-claude-max-tokens= :: Maximum tokens to generate (nil
  for API default).

  #+begin_src example-preformatted
  (setq ollama-buddy-claude-max-tokens 2000)
  #+end_src

<<History-Management>>
*** 14.5 History Management [[#History-Management][¶]]
:PROPERTIES:
:CUSTOM_ID: history-management
:CLASS: section
:END:
Each API service maintains its own conversation history:

- Ollama history for local models
- OpenAI history for ChatGPT models
- Claude history for Claude models

This ensures that context is maintained appropriately for each service.

<<Improved-Error-Handling>>
*** 14.6 Improved Error Handling [[#Improved-Error-Handling][¶]]
:PROPERTIES:
:CUSTOM_ID: improved-error-handling
:CLASS: section
:END:
As of version 0.9.20, Ollama Buddy includes enhanced error handling for
ChatGPT and Claude:

- Better Unicode character handling in JSON requests
- More robust error recovery
- Clearer error messages
- Consistent handling of API responses

--------------

<<Advanced-Usage>>

Next: [[#API-Reference][API Reference]], Previous:
[[#ChatGPT-and-Claude-Support][ChatGPT and Claude Support]], Up:
[[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 15 Advanced Usage [[#Advanced-Usage-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Advanced-Usage-1
:CLASS: chapter
:END:
- [[#Managing-Token-Usage][Managing Token Usage]]
- [[#Customizing-the-Interface][Customizing the Interface]]
- [[#Editing-Conversation-History][Editing Conversation History]]
- [[#Advanced-System-Prompt-Management][Advanced System Prompt
  Management]]
- [[#Using-Direct-API-Access][Using Direct API Access]]

<<Managing-Token-Usage>>
*** 15.1 Managing Token Usage [[#Managing-Token-Usage][¶]]
:PROPERTIES:
:CUSTOM_ID: managing-token-usage
:CLASS: section
:END:
Ollama Buddy can track token usage statistics:

To toggle token statistics display after responses:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-token-display
#+end_src

or press =C-c T= in the chat buffer.

To view detailed token usage statistics:

#+begin_src example-preformatted
M-x ollama-buddy-display-token-stats
#+end_src

or press =C-c u= in the chat buffer.

To display a visual graph of token usage:

#+begin_src example-preformatted
M-x ollama-buddy-display-token-graph
#+end_src

or press =C-c U= in the chat buffer.

<<Customizing-the-Interface>>
*** 15.2 Customizing the Interface [[#Customizing-the-Interface][¶]]
:PROPERTIES:
:CUSTOM_ID: customizing-the-interface
:CLASS: section
:END:
- [[#Interface-Level][Interface Level]]
- [[#Model-Colors][Model Colors]]
- [[#Debug-Mode][Debug Mode]]

<<Interface-Level>>
**** 15.2.1 Interface Level [[#Interface-Level][¶]]
:PROPERTIES:
:CUSTOM_ID: interface-level
:CLASS: subsection
:END:
Ollama Buddy has two interface levels:

- basic - Simplified for beginners
- advanced - Full feature set for power users

To toggle between them:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-interface-level
#+end_src

or press =C-c A= in the chat buffer.

<<Model-Colors>>
**** 15.2.2 Model Colors [[#Model-Colors][¶]]
:PROPERTIES:
:CUSTOM_ID: model-colors
:CLASS: subsection
:END:
Each model has a distinctive color to help identify responses.

To toggle model colors:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-model-colors
#+end_src

or press =C-c c= in the chat buffer.

<<Debug-Mode>>
**** 15.2.3 Debug Mode [[#Debug-Mode][¶]]
:PROPERTIES:
:CUSTOM_ID: debug-mode
:CLASS: subsection
:END:
For advanced troubleshooting, you can enable debug mode:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-debug-mode
#+end_src

or press =C-c B= in the chat buffer.

This shows raw JSON messages in a debug buffer.

<<Editing-Conversation-History>>
*** 15.3 Editing Conversation History [[#Editing-Conversation-History][¶]]
:PROPERTIES:
:CUSTOM_ID: editing-conversation-history
:CLASS: section
:END:
To manually edit conversation history:

#+begin_src example-preformatted
M-x ollama-buddy-history-edit
#+end_src

or press =C-c J= in the chat buffer.

This opens an editable buffer with the conversation history. You can
modify it and press =C-c C-c= to save or =C-c C-k= to cancel.

To edit history for a specific model, use =C-u C-c J=.

<<Advanced-System-Prompt-Management>>
*** 15.4 Advanced System Prompt Management [[#Advanced-System-Prompt-Management][¶]]
:PROPERTIES:
:CUSTOM_ID: advanced-system-prompt-management
:CLASS: section
:END:
For more control over system prompts:

- [[#Setting-a-system-prompt-without-sending][Setting a system prompt
  without sending]]
- [[#Using-a-system-prompt-from-Fabric][Using a system prompt from
  Fabric]]

<<Setting-a-system-prompt-without-sending>>
**** 15.4.1 Setting a system prompt without sending [[#Setting-a-system-prompt-without-sending][¶]]
:PROPERTIES:
:CUSTOM_ID: setting-a-system-prompt-without-sending
:CLASS: subsection
:END:

#+begin_src example-preformatted
(ollama-buddy-set-system-prompt)
#+end_src

Enter your system prompt, then press =C-c s=.

<<Using-a-system-prompt-from-Fabric>>
**** 15.4.2 Using a system prompt from Fabric [[#Using-a-system-prompt-from-Fabric][¶]]
:PROPERTIES:
:CUSTOM_ID: using-a-system-prompt-from-fabric
:CLASS: subsection
:END:

#+begin_src example-preformatted
M-x ollama-buddy-fabric-set-system-prompt
#+end_src

or press =C-c f p=.

<<Using-Direct-API-Access>>
*** 15.5 Using Direct API Access [[#Using-Direct-API-Access][¶]]
:PROPERTIES:
:CUSTOM_ID: using-direct-api-access
:CLASS: section
:END:
For direct programmatic access to Ollama:

#+begin_src example-preformatted
(ollama-buddy--make-request "/api/tags" "GET")
#+end_src

Or with a payload:

#+begin_src example-preformatted
(ollama-buddy--make-request "/api/chat" "POST" 
                           (json-encode '((model . "llama3:latest")
                                         (prompt . "Hello"))))
#+end_src

--------------

<<API-Reference>>

Next: [[#FAQ][Frequently Asked Questions]], Previous:
[[#Advanced-Usage][Advanced Usage]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 16 API Reference [[#API-Reference-1][¶]]
:PROPERTIES:
:CUSTOM_ID: API-Reference-1
:CLASS: chapter
:END:
- [[#Interactive-Functions][Interactive Functions]]
- [[#Core-Functions][Core Functions]]
- [[#Customization-Functions][Customization Functions]]

<<Interactive-Functions>>
*** 16.1 Interactive Functions [[#Interactive-Functions][¶]]
:PROPERTIES:
:CUSTOM_ID: interactive-functions
:CLASS: section
:END:
- =ollama-buddy-menu= :: Display the main Ollama Buddy menu.

- =ollama-buddy-transient-menu= :: Display the transient-based menu.

- =ollama-buddy--open-chat= :: Open the chat buffer.

- =ollama-buddy--send-prompt= :: Send the current prompt to the AI.

- =ollama-buddy--swap-model= :: Switch to a different model.

- =ollama-buddy-manage-models= :: Display and manage available models.

- =ollama-buddy-pull-model= :: Pull a new model from Ollama Hub.

- =ollama-buddy-import-gguf-file= :: Import a GGUF file to create a
  custom model.

- =ollama-buddy-set-system-prompt= :: Set the current prompt as the
  system prompt.

- =ollama-buddy-reset-system-prompt= :: Reset the system prompt to
  default (none).

- =ollama-buddy-sessions-save= :: Save the current conversation as a
  session.

- =ollama-buddy-sessions-load= :: Load a previously saved session.

- =ollama-buddy-sessions-list= :: Display a list of saved sessions.

- =ollama-buddy-sessions-delete= :: Delete a saved session.

- =ollama-buddy-sessions-new= :: Start a new session.

- =ollama-buddy-toggle-history= :: Toggle conversation history on/off.

- =ollama-buddy-clear-history= :: Clear the conversation history.

- =ollama-buddy-history-edit= :: Display the conversation history.

- =ollama-buddy-roles-switch-role= :: Switch to a different role.

- =ollama-buddy-role-creator-create-new-role= :: Create a new role.

- =ollama-buddy-params-display= :: Display current parameter settings.

- =ollama-buddy-params-edit= :: Edit a specific parameter.

- =ollama-buddy-params-reset= :: Reset all parameters to defaults.

- =ollama-buddy-toggle-params-in-header= :: Toggle display of parameters
  in header.

- =ollama-buddy-toggle-token-display= :: Toggle display of token
  statistics.

- =ollama-buddy-display-token-stats= :: Display token usage statistics.

- =ollama-buddy-display-token-graph= :: Display a visual graph of token
  usage.

- =ollama-buddy-fabric-setup= :: Set up Fabric pattern integration.

- =ollama-buddy-fabric-sync-patterns= :: Sync with the latest Fabric
  patterns.

- =ollama-buddy-fabric-list-patterns= :: List available Fabric patterns.

- =ollama-buddy-fabric-send= :: Apply a Fabric pattern to selected text.

- =ollama-buddy-toggle-markdown-conversion= :: Toggle Markdown to Org
  conversion.

- =ollama-buddy-toggle-debug-mode= :: Toggle display of debug
  information.

- =ollama-buddy-set-model-context-size= :: Set the context size for a
  specific model.

- =ollama-buddy-toggle-context-percentage= :: Toggle context percentage
  display in the status bar.

- =ollama-buddy-show-context-info= :: Display detailed context usage
  information.

- =ollama-buddy-set-max-history-length= :: Set the maximum number of
  message pairs to keep in history.

<<Core-Functions>>
*** 16.2 Core Functions [[#Core-Functions][¶]]
:PROPERTIES:
:CUSTOM_ID: core-functions
:CLASS: section
:END:
- =ollama-buddy--send= :: Send a prompt to Ollama.

- =ollama-buddy--make-request= :: Make a generic request to the Ollama
  API.

- =ollama-buddy--get-models= :: Get a list of available models.

- =ollama-buddy--get-valid-model= :: Get a valid model with fallback
  handling.

- =ollama-buddy--add-to-history= :: Add a message to the conversation
  history.

- =ollama-buddy--get-history-for-request= :: Get history for the current
  request.

- =ollama-buddy--prepare-prompt-area= :: Prepare the prompt area in the
  buffer.

- =ollama-buddy--update-status= :: Update the status display.

<<Customization-Functions>>
*** 16.3 Customization Functions [[#Customization-Functions][¶]]
:PROPERTIES:
:CUSTOM_ID: customization-functions
:CLASS: section
:END:
- =ollama-buddy-update-command-with-params= :: Update a command
  definition with new properties and parameters.

- =ollama-buddy-update-menu-entry= :: Update a menu entry's properties.

- =ollama-buddy-add-model-to-menu-entry= :: Associate a specific model
  with a menu entry.

- =ollama-buddy-add-parameters-to-command= :: Add specific parameters to
  a command definition.

--------------

<<FAQ>>

Next: [[#Troubleshooting][Troubleshooting]], Previous:
[[#API-Reference][API Reference]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 17 Frequently Asked Questions [[#Frequently-Asked-Questions][¶]]
:PROPERTIES:
:CUSTOM_ID: Frequently-Asked-Questions
:CLASS: chapter
:END:
- [[#General-Questions][General Questions]]
- [[#Usage-Questions][Usage Questions]]
- [[#Troubleshooting-1][Troubleshooting]]

<<General-Questions>>
*** 17.1 General Questions [[#General-Questions][¶]]
:PROPERTIES:
:CUSTOM_ID: general-questions
:CLASS: section
:END:
- [[#What-is-the-difference-between-Ollama-Buddy-and-other-AI-assistants_003f][What
  is the difference between Ollama Buddy and other AI assistants?]]
- [[#Does-Ollama-Buddy-require-an-internet-connection_003f][Does Ollama
  Buddy require an internet connection?]]
- [[#Which-models-work-best-with-Ollama-Buddy_003f][Which models work
  best with Ollama Buddy?]]
- [[#How-much-RAM-do-I-need_003f][How much RAM do I need?]]

<<What-is-the-difference-between-Ollama-Buddy-and-other-AI-assistants_003f>>
**** 17.1.1 What is the difference between Ollama Buddy and other AI assistants? [[#What-is-the-difference-between-Ollama-Buddy-and-other-AI-assistants_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: what-is-the-difference-between-ollama-buddy-and-other-ai-assistants
:CLASS: subsection
:END:
Ollama Buddy integrates with Ollama to run LLMs locally, offering
privacy, customization, and seamless Emacs integration without relying
on external API services.

<<Does-Ollama-Buddy-require-an-internet-connection_003f>>
**** 17.1.2 Does Ollama Buddy require an internet connection? [[#Does-Ollama-Buddy-require-an-internet-connection_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: does-ollama-buddy-require-an-internet-connection
:CLASS: subsection
:END:
Once you've installed Ollama and pulled your models, no internet
connection is required for normal operation. Internet is only needed
when pulling new models or syncing Fabric patterns.

<<Which-models-work-best-with-Ollama-Buddy_003f>>
**** 17.1.3 Which models work best with Ollama Buddy? [[#Which-models-work-best-with-Ollama-Buddy_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: which-models-work-best-with-ollama-buddy
:CLASS: subsection
:END:
Most models supported by Ollama work well. Popular choices include:

- llama3:latest - Good general purpose assistant
- codellama:latest - Excellent for code-related tasks
- mistral:latest - Good balance of performance and quality
- phi:latest - Smaller model that works well on limited hardware

<<How-much-RAM-do-I-need_003f>>
**** 17.1.4 How much RAM do I need? [[#How-much-RAM-do-I-need_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: how-much-ram-do-i-need
:CLASS: subsection
:END:
It depends on the model:

- Small models (7B) - 8GB minimum, 16GB recommended
- Medium models (13B) - 16GB minimum, 24GB+ recommended
- Large models (34B+) - 32GB+ recommended

Quantized models (e.g., Q4_K_M variants) require less RAM.

<<Usage-Questions>>
*** 17.2 Usage Questions [[#Usage-Questions][¶]]
:PROPERTIES:
:CUSTOM_ID: usage-questions
:CLASS: section
:END:
- [[#How-do-I-cancel-a-request-that_0027s-taking-too-long_003f][How do I
  cancel a request that's taking too long?]]
- [[#How-can-I-save-my-conversations_003f][How can I save my
  conversations?]]
- [[#Can-I-use-multiple-models-in-the-same-conversation_003f][Can I use
  multiple models in the same conversation?]]
- [[#How-do-I-clear-the-conversation-history_003f][How do I clear the
  conversation history?]]
- [[#How-can-I-create-a-custom-command_003f][How can I create a custom
  command?]]
- [[#How-can-I-manage-context-windows_003f][How can I manage context
  windows?]]
- [[#What-happens-when-I-exceed-the-context-limit_003f][What happens
  when I exceed the context limit?]]

<<How-do-I-cancel-a-request-that_0027s-taking-too-long_003f>>
**** 17.2.1 How do I cancel a request that's taking too long? [[#How-do-I-cancel-a-request-that_0027s-taking-too-long_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: how-do-i-cancel-a-request-thats-taking-too-long
:CLASS: subsection
:END:
Press =C-c k= in the chat buffer or select "Kill Request" from the menu.

<<How-can-I-save-my-conversations_003f>>
**** 17.2.2 How can I save my conversations? [[#How-can-I-save-my-conversations_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: how-can-i-save-my-conversations
:CLASS: subsection
:END:
Use =C-c S= to save the current session, giving it a name. You can
restore it later with =C-c L=.

<<Can-I-use-multiple-models-in-the-same-conversation_003f>>
**** 17.2.3 Can I use multiple models in the same conversation? [[#Can-I-use-multiple-models-in-the-same-conversation_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: can-i-use-multiple-models-in-the-same-conversation
:CLASS: subsection
:END:
Yes, you can switch models at any time with =C-c m=. Each model
maintains its own conversation history.

<<How-do-I-clear-the-conversation-history_003f>>
**** 17.2.4 How do I clear the conversation history? [[#How-do-I-clear-the-conversation-history_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: how-do-i-clear-the-conversation-history
:CLASS: subsection
:END:
Press =C-c X= to clear history, or =C-c N= to start a completely new
session.

<<How-can-I-create-a-custom-command_003f>>
**** 17.2.5 How can I create a custom command? [[#How-can-I-create-a-custom-command_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: how-can-i-create-a-custom-command
:CLASS: subsection
:END:
The easiest way is through the role creator: press =C-c E= and follow
the prompts to create commands with specific prompts, models, and
parameters.

<<How-can-I-manage-context-windows_003f>>
**** 17.2.6 How can I manage context windows? [[#How-can-I-manage-context-windows_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: how-can-i-manage-context-windows
:CLASS: subsection
:END:
Ollama Buddy provides several options:

- Enable context monitoring with
  =(setq ollama-buddy-show-context-percentage t)=
- Use C-c C to check current context usage
- Limit history length with C-c Y
- Set model-specific context sizes with C-c $

<<What-happens-when-I-exceed-the-context-limit_003f>>
**** 17.2.7 What happens when I exceed the context limit? [[#What-happens-when-I-exceed-the-context-limit_003f][¶]]
:PROPERTIES:
:CUSTOM_ID: what-happens-when-i-exceed-the-context-limit
:CLASS: subsection
:END:
When context monitoring is enabled:

- You'll get a warning when approaching the limit (85-100%)
- You'll get an error dialog at or above 100%
- You can choose to proceed anyway or modify your content

<<Troubleshooting-1>>
*** 17.3 Troubleshooting [[#Troubleshooting-1][¶]]
:PROPERTIES:
:CUSTOM_ID: troubleshooting
:CLASS: section
:END:
- [[#Ollama-Buddy-shows-_0022OFFLINE_0022-status][Ollama Buddy shows
  "OFFLINE" status]]
- [[#Responses-are-slow-or-the-model-seems-to-hang][Responses are slow
  or the model seems to hang]]
- [[#Getting-_0022error-parsing-model_0022-when-pulling-a-model][Getting
  "error parsing model" when pulling a model]]
- [[#Model-responses-are-low-quality-or-truncated][Model responses are
  low quality or truncated]]

<<Ollama-Buddy-shows-_0022OFFLINE_0022-status>>
**** 17.3.1 Ollama Buddy shows "OFFLINE" status [[#Ollama-Buddy-shows-_0022OFFLINE_0022-status][¶]]
:PROPERTIES:
:CUSTOM_ID: ollama-buddy-shows-offline-status
:CLASS: subsection
:END:
Ensure that:

- Ollama is installed and running
- The hostname and port are correctly configured (=ollama-buddy-host=
  and =ollama-buddy-port=)
- Your firewall isn't blocking connections

<<Responses-are-slow-or-the-model-seems-to-hang>>
**** 17.3.2 Responses are slow or the model seems to hang [[#Responses-are-slow-or-the-model-seems-to-hang][¶]]
:PROPERTIES:
:CUSTOM_ID: responses-are-slow-or-the-model-seems-to-hang
:CLASS: subsection
:END:
Try:

- Using a smaller model
- Adjusting the =num_ctx= parameter to a smaller value
- Setting =low_vram= to =t= if you have limited GPU memory
- Checking CPU/RAM usage to ensure your system isn't overloaded

<<Getting-_0022error-parsing-model_0022-when-pulling-a-model>>
**** 17.3.3 Getting "error parsing model" when pulling a model [[#Getting-_0022error-parsing-model_0022-when-pulling-a-model][¶]]
:PROPERTIES:
:CUSTOM_ID: getting-error-parsing-model-when-pulling-a-model
:CLASS: subsection
:END:
This usually means:

- The model name is incorrect
- The model is not available in the Ollama repository
- You have network connectivity issues

<<Model-responses-are-low-quality-or-truncated>>
**** 17.3.4 Model responses are low quality or truncated [[#Model-responses-are-low-quality-or-truncated][¶]]
:PROPERTIES:
:CUSTOM_ID: model-responses-are-low-quality-or-truncated
:CLASS: subsection
:END:
Try:

- Increasing the =temperature= parameter for more creative responses
- Increasing =num_predict= for longer responses
- Using a more capable model
- Providing clearer instructions in your prompt

--------------

<<Troubleshooting>>

Next: [[#Contributing][Contributing]], Previous: [[#FAQ][Frequently
Asked Questions]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 18 Troubleshooting [[#Troubleshooting-2][¶]]
:PROPERTIES:
:CUSTOM_ID: Troubleshooting-2
:CLASS: chapter
:END:
- [[#Common-Issues][Common Issues]]
- [[#Debugging][Debugging]]

<<Common-Issues>>
*** 18.1 Common Issues [[#Common-Issues][¶]]
:PROPERTIES:
:CUSTOM_ID: common-issues
:CLASS: section
:END:
- [[#Connection-Problems][Connection Problems]]
- [[#Model-Problems][Model Problems]]
- [[#Interface-Issues][Interface Issues]]

<<Connection-Problems>>
**** 18.1.1 Connection Problems [[#Connection-Problems][¶]]
:PROPERTIES:
:CUSTOM_ID: connection-problems
:CLASS: subsection
:END:
- Symptom: Unable to connect to Ollama server :: - Check if Ollama is
    running with =ps aux | grep ollama=
  - Verify host and port settings (=ollama-buddy-host= and
    =ollama-buddy-port=)
  - Try connecting to Ollama directly:
    =curl http://localhost:11434/api/tags=
- Symptom: Connection breaks during long responses :: - This can happen
    with very large responses
  - Try setting a lower =num_predict= value
  - Check if your OS has any network timeout settings

<<Model-Problems>>
**** 18.1.2 Model Problems [[#Model-Problems][¶]]
:PROPERTIES:
:CUSTOM_ID: model-problems
:CLASS: subsection
:END:
- Symptom: Model loads but gives poor responses :: - Try a different
    model
  - Adjust parameters (increase temperature for more creativity)
  - Provide clearer or more detailed prompts
  - Check if the model is appropriate for your task
- Symptom: Model fails to load or crashes :: - Check system memory usage
  - Try a smaller quantized model
  - Adjust =num_ctx= to a smaller value
  - Set =low_vram= to =t= if using GPU

<<Interface-Issues>>
**** 18.1.3 Interface Issues [[#Interface-Issues][¶]]
:PROPERTIES:
:CUSTOM_ID: interface-issues
:CLASS: subsection
:END:
- Symptom: Chat buffer becomes unresponsive :: - Cancel any running
    requests with =C-c k=
  - Check if Emacs is using high CPU
  - Try disabling token statistics display
  - Close and reopen the chat buffer
- Symptom: Markdown conversion issues :: - Toggle markdown conversion
    off with =C-c C-o=
  - Check if the response contains complex formatting
  - Try editing the history to fix formatting issues

<<Debugging>>
*** 18.2 Debugging [[#Debugging][¶]]
:PROPERTIES:
:CUSTOM_ID: debugging
:CLASS: section
:END:
- [[#Enable-Debug-Mode][Enable Debug Mode]]
- [[#Check-Logs][Check Logs]]
- [[#Report-Issues][Report Issues]]

<<Enable-Debug-Mode>>
**** 18.2.1 Enable Debug Mode [[#Enable-Debug-Mode][¶]]
:PROPERTIES:
:CUSTOM_ID: enable-debug-mode
:CLASS: subsection
:END:
To get more information about what's happening:

#+begin_src example-preformatted
M-x ollama-buddy-toggle-debug-mode
#+end_src

This opens a debug buffer showing raw JSON communication with Ollama.

<<Check-Logs>>
**** 18.2.2 Check Logs [[#Check-Logs][¶]]
:PROPERTIES:
:CUSTOM_ID: check-logs
:CLASS: subsection
:END:
Ollama logs can be useful for troubleshooting:

#+begin_src example-preformatted
tail -f ~/.ollama/logs/ollama.log
#+end_src

<<Report-Issues>>
**** 18.2.3 Report Issues [[#Report-Issues][¶]]
:PROPERTIES:
:CUSTOM_ID: report-issues
:CLASS: subsection
:END:
If you encounter a bug:

1. Enable debug mode
2. Reproduce the issue
3. Copy the debug output
4. Report the issue on GitHub with:
   - Emacs version
   - Ollama version
   - Model used
   - Debug output
   - Steps to reproduce

--------------

<<Contributing>>

Next: [[#Index][Index]], Previous:
[[#Troubleshooting][Troubleshooting]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** 19 Contributing [[#Contributing-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Contributing-1
:CLASS: chapter
:END:
- [[#Getting-Started][Getting Started]]
- [[#Development-Setup][Development Setup]]
- [[#Coding-Guidelines][Coding Guidelines]]
- [[#Testing][Testing]]
- [[#Feature-Requests-and-Bug-Reports][Feature Requests and Bug
  Reports]]

<<Getting-Started>>
*** 19.1 Getting Started [[#Getting-Started][¶]]
:PROPERTIES:
:CUSTOM_ID: getting-started
:CLASS: section
:END:
Ollama Buddy is an open-source project, and contributions are welcome!

1. Fork the repository:
   [[https://github.com/captainflasmr/ollama-buddy]]
2. Clone your fork:
   =git clone https://github.com/YOUR-USERNAME/ollama-buddy.git=
3. Create a branch: =git checkout -b my-feature-branch=
4. Make your changes
5. Test thoroughly
6. Commit with a clear message
7. Push to your fork
8. Create a pull request

<<Development-Setup>>
*** 19.2 Development Setup [[#Development-Setup][¶]]
:PROPERTIES:
:CUSTOM_ID: development-setup
:CLASS: section
:END:
- [[#Required-Tools][Required Tools]]
- [[#Recommended-Packages][Recommended Packages]]

<<Required-Tools>>
**** 19.2.1 Required Tools [[#Required-Tools][¶]]
:PROPERTIES:
:CUSTOM_ID: required-tools
:CLASS: subsection
:END:
- Emacs 28.1+
- Ollama installed and running
- Git

<<Recommended-Packages>>
**** 19.2.2 Recommended Packages [[#Recommended-Packages][¶]]
:PROPERTIES:
:CUSTOM_ID: recommended-packages
:CLASS: subsection
:END:
- package-lint
- flycheck
- elisp-lint

<<Coding-Guidelines>>
*** 19.3 Coding Guidelines [[#Coding-Guidelines][¶]]
:PROPERTIES:
:CUSTOM_ID: coding-guidelines
:CLASS: section
:END:
- Follow Emacs Lisp conventions
- Use two spaces for indentation
- Add documentation strings to functions
- Keep line length under 80 characters
- Use prefix =ollama-buddy--= for internal functions
- Use prefix =ollama-buddy-= for public functions

<<Testing>>
*** 19.4 Testing [[#Testing][¶]]
:PROPERTIES:
:CUSTOM_ID: testing
:CLASS: section
:END:
- [[#Run-Existing-Tests][Run Existing Tests]]
- [[#Adding-New-Tests][Adding New Tests]]

<<Run-Existing-Tests>>
**** 19.4.1 Run Existing Tests [[#Run-Existing-Tests][¶]]
:PROPERTIES:
:CUSTOM_ID: run-existing-tests
:CLASS: subsection
:END:
The package includes comprehensive tests:

#+begin_src example-preformatted
M-x ollama-buddy-run-tests
M-x ollama-buddy-integration-run-tests
M-x ollama-buddy-fabric-run-tests
M-x ollama-buddy-parameter-run-tests
#+end_src

<<Adding-New-Tests>>
**** 19.4.2 Adding New Tests [[#Adding-New-Tests][¶]]
:PROPERTIES:
:CUSTOM_ID: adding-new-tests
:CLASS: subsection
:END:
When adding features, please also add tests:

- Unit tests for individual functions
- Integration tests for API interactions
- Parameter tests for parameter handling

<<Feature-Requests-and-Bug-Reports>>
*** 19.5 Feature Requests and Bug Reports [[#Feature-Requests-and-Bug-Reports][¶]]
:PROPERTIES:
:CUSTOM_ID: feature-requests-and-bug-reports
:CLASS: section
:END:
- Use GitHub Issues for bug reports and feature requests
- Provide clear steps to reproduce bugs
- For feature requests, explain the use case

--------------

<<Index>>

Previous: [[#Contributing][Contributing]], Up: [[#Top][Ollama Buddy]]  
[[[#SEC_Contents][Contents]]][[[#Index][Index]]]

** Index [[#Index-1][¶]]
:PROPERTIES:
:CUSTOM_ID: Index-1
:CLASS: unnumbered
:END:
